{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from random import randint\n",
    " \n",
    "import gc \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import nibabel as nib\n",
    "import pydicom as pdm\n",
    "import nilearn as nl\n",
    "import nilearn.plotting as nlplt\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from skimage.util import montage\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import Compose, HorizontalFlip\n",
    "\n",
    "\n",
    "from monai.metrics.utils import do_metric_reduction\n",
    "from monai.metrics.utils import get_mask_edges, get_surface_distance\n",
    "from monai.metrics import CumulativeIterationMetric\n",
    "\n",
    "from medcam import medcam\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an example of the 3D Brain MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "sample_filename = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\\BraTS20_Training_275\\BraTS20_Training_275_flair.nii'\n",
    "sample_filename_mask = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\\BraTS20_Training_275\\BraTS20_Training_275_seg.nii'\n",
    "\n",
    "sample_img = nib.load(sample_filename)\n",
    "sample_img = np.asanyarray(sample_img.dataobj)\n",
    "sample_img = np.rot90(sample_img)\n",
    "sample_mask = nib.load(sample_filename_mask)\n",
    "sample_mask = np.asanyarray(sample_mask.dataobj)\n",
    "sample_mask = np.rot90(sample_mask)\n",
    "print(\"img shape ->\", sample_img.shape)\n",
    "print(\"mask shape ->\", sample_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_filename2 = r'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_275/BraTS20_Training_275_t1.nii'\n",
    "sample_img2 = nib.load(sample_filename2)\n",
    "sample_img2 = np.asanyarray(sample_img2.dataobj)\n",
    "sample_img2  = np.rot90(sample_img2)\n",
    "\n",
    "sample_filename3 = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\\BraTS20_Training_275\\BraTS20_Training_275_t2.nii'\n",
    "sample_img3 = nib.load(sample_filename3)\n",
    "sample_img3 = np.asanyarray(sample_img3.dataobj)\n",
    "sample_img3  = np.rot90(sample_img3)\n",
    "\n",
    "sample_filename4 = r'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_275/BraTS20_Training_275_t1ce.nii'\n",
    "sample_img4 = nib.load(sample_filename4)\n",
    "sample_img4 = np.asanyarray(sample_img4.dataobj)\n",
    "sample_img4  = np.rot90(sample_img4)\n",
    "\n",
    "# WHOLE TUOMUR / ED - LABEL 2 \n",
    "mask_WT = sample_mask.copy()\n",
    "mask_WT[mask_WT == 1] = 1\n",
    "mask_WT[mask_WT == 2] = 1\n",
    "mask_WT[mask_WT == 4] = 1\n",
    "\n",
    "# NCR OR NET - LABEL 1 \n",
    "mask_TC = sample_mask.copy()\n",
    "mask_TC[mask_TC == 1] = 1\n",
    "mask_TC[mask_TC == 2] = 0\n",
    "mask_TC[mask_TC == 4] = 1\n",
    "\n",
    "# ET - LABEL 4 \n",
    "mask_ET = sample_mask.copy()\n",
    "mask_ET[mask_ET == 1] = 0\n",
    "mask_ET[mask_ET == 2] = 0\n",
    "mask_ET[mask_ET == 4] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a slice of the Brain Tumour and the MRIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://matplotlib.org/3.3.2/gallery/images_contours_and_fields/plot_streamplot.html#sphx-glr-gallery-images-contours-and-fields-plot-streamplot-py\n",
    "# https://stackoverflow.com/questions/25482876/how-to-add-legend-to-imshow-in-matplotlib\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "gs = gridspec.GridSpec(nrows=2, ncols=4, height_ratios=[1, 1]) # create the space in which the images will be plotted (2 rows, 4 columns, second row 2 times the height of the first row)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "flair = ax0.imshow(sample_img[:,:,70], cmap='bone')\n",
    "ax0.set_title(\"FLAIR\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(flair)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "t1 = ax1.imshow(sample_img2[:,:,70], cmap='bone')\n",
    "ax1.set_title(\"T1\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(t1)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "t2 = ax2.imshow(sample_img3[:,:,70], cmap='bone')\n",
    "ax2.set_title(\"T2\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(t2)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax3 = fig.add_subplot(gs[0, 3])\n",
    "t1ce = ax3.imshow(sample_img4[:,:,70], cmap='bone')\n",
    "ax3.set_title(\"T1 contrast\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(t1ce)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax4 = fig.add_subplot(gs[1, 0:4])\n",
    "\n",
    "#ax4.imshow(np.ma.masked_where(mask_WT[:,:,65]== False,  mask_WT[:,:,65]), cmap='summer', alpha=0.6)\n",
    "l1 = ax4.imshow(mask_WT[:,:,70], cmap='summer',)\n",
    "l2 = ax4.imshow(np.ma.masked_where(mask_TC[:,:,70]== False,  mask_TC[:,:,70]), cmap='rainbow', alpha=0.6) # creating segmentation with tumour core\n",
    "l3 = ax4.imshow(np.ma.masked_where(mask_ET[:,:,70] == False, mask_ET[:,:,70]), cmap='winter', alpha=0.6) # creating segmentation with enhancing tumour\n",
    "\n",
    "ax4.set_title(\"Segmented Mask\", fontsize=20, weight='bold', y=-0.1)\n",
    "\n",
    "_ = [ax.set_axis_off() for ax in [ax0,ax1,ax2,ax3, ax4]] # removes the numbers (pixel values) from the y and x axis\n",
    "\n",
    "colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]] # Generate colours based on normalizing the values between 0 to 1 for each image of the segmented mask\n",
    "\n",
    "\n",
    "labels = ['Non-Enhancing tumor core', 'Peritumoral Edema ', 'GD-enhancing tumor']\n",
    "patches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 'xx-large',\n",
    "           title='Mask Labels', title_fontsize=18, edgecolor=\"black\",  facecolor='#c5c6c7')\n",
    "\n",
    "plt.suptitle(\"Multimodal Scans -  Data | Manually-segmented mask - Target\", fontsize=20, weight='bold')\n",
    "\n",
    "# fig.savefig(\"data_sample.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\n",
    "# fig.savefig(\"data_sample.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a 3D GIF of the Brain Tumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image3dToGIF3d:\n",
    "    \"\"\"\n",
    "    Displaying 3D images in 3d axes.\n",
    "    Parameters:\n",
    "        img_dim: shape of cube for resizing.\n",
    "        figsize: figure size for plotting in inches.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 img_dim: tuple = (55, 55, 55), #Image dimension size\n",
    "                 figsize: tuple = (15, 10), #size of image output\n",
    "                 binary: bool = False, \n",
    "                 normalizing: bool = True,\n",
    "                ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.img_dim = img_dim\n",
    "        print(img_dim)\n",
    "        self.figsize = figsize\n",
    "        self.binary = binary\n",
    "        self.normalizing = normalizing\n",
    "\n",
    "    def _explode(self, data: np.ndarray):\n",
    "        \"\"\"\n",
    "        Takes: array and return an array twice as large in each dimension,\n",
    "        with an extra space between each voxel.\n",
    "        \"\"\"\n",
    "        shape_arr = np.array(data.shape)\n",
    "        size = shape_arr[:3] * 2 - 1\n",
    "        exploded = np.zeros(np.concatenate([size, shape_arr[3:]]),\n",
    "                            dtype=data.dtype)\n",
    "        exploded[::2, ::2, ::2] = data\n",
    "        return exploded\n",
    "\n",
    "    def _expand_coordinates(self, indices: np.ndarray):\n",
    "        x, y, z = indices\n",
    "        x[1::2, :, :] += 1\n",
    "        y[:, 1::2, :] += 1\n",
    "        z[:, :, 1::2] += 1\n",
    "        return x, y, z\n",
    "    \n",
    "    def _normalize(self, arr: np.ndarray):\n",
    "        \"\"\"Normilize image value between 0 and 1.\"\"\"\n",
    "        arr_min = np.min(arr)\n",
    "        return (arr - arr_min) / (np.max(arr) - arr_min)\n",
    "\n",
    "    \n",
    "    def _scale_by(self, arr: np.ndarray, factor: int):\n",
    "        \"\"\"\n",
    "        Scale 3d Image to factor.\n",
    "        Parameters:\n",
    "            arr: 3d image for scalling.\n",
    "            factor: factor for scalling.\n",
    "        \"\"\"\n",
    "        mean = np.mean(arr)\n",
    "        return (arr - mean) * factor + mean \n",
    "        # the mean is added back to the scaled array ((arr - mean) * factor + mean). \n",
    "        # This step ensures that the mean value of the resulting array remains unchanged after scaling.\n",
    "    \n",
    "    def get_transformed_data(self, data: np.ndarray):\n",
    "        \"\"\"Data transformation: normalization, scaling, resizing.\"\"\"\n",
    "        if self.binary:\n",
    "            resized_data = resize(data, self.img_dim, preserve_range=True)\n",
    "            return np.clip(resized_data.astype(np.uint8), 0, 1).astype(np.float32)\n",
    "            \n",
    "        norm_data = np.clip(self._normalize(data)-0.1, 0, 1) ** 0.4\n",
    "        scaled_data = np.clip(self._scale_by(norm_data, 2) - 0.1, 0, 1)\n",
    "        resized_data = resize(scaled_data, self.img_dim, preserve_range=True)\n",
    "        \n",
    "        return resized_data\n",
    "    \n",
    "    def plot_cube(self,\n",
    "                  cube,\n",
    "                  title: str = '', \n",
    "                  init_angle: int = 0,\n",
    "                  make_gif: bool = False,\n",
    "                  path_to_save: str = 'filename.gif'\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Plot 3d data.\n",
    "        Parameters:\n",
    "            cube: 3d data\n",
    "            title: title for figure.\n",
    "            init_angle: angle for image plot (from 0-360).\n",
    "            make_gif: if True create gif from every 5th frames from 3d image plot.\n",
    "            path_to_save: path to save GIF file.\n",
    "            \"\"\"\n",
    "        if self.binary:\n",
    "            facecolors = cm.winter(cube)\n",
    "            print(\"binary\")\n",
    "        else:\n",
    "            if self.normalizing:\n",
    "                cube = self._normalize(cube)\n",
    "            facecolors = cm.gist_stern(cube)\n",
    "            print(\"not binary\")\n",
    "            \n",
    "        facecolors[:,:,:,-1] = cube\n",
    "        facecolors = self._explode(facecolors)\n",
    "\n",
    "        filled = facecolors[:,:,:,-1] != 0\n",
    "        x, y, z = self._expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "        with plt.style.context(\"dark_background\"):\n",
    "\n",
    "            fig = plt.figure(figsize=self.figsize)\n",
    "            ax = fig.add_subplot(projection = '3d')\n",
    "\n",
    "            ax.view_init(30, init_angle)\n",
    "            ax.set_xlim(right = self.img_dim[0] * 2)\n",
    "            ax.set_ylim(top = self.img_dim[1] * 2)\n",
    "            ax.set_zlim(top = self.img_dim[2] * 2)\n",
    "            ax.set_title(title, fontsize=18, y=1.05)\n",
    "\n",
    "            ax.voxels(x, y, z, filled, facecolors=facecolors, shade=False)\n",
    "\n",
    "            if make_gif:\n",
    "                images = []\n",
    "                for angle in tqdm(range(0, 360, 5)):\n",
    "                    ax.view_init(30, angle)\n",
    "                    fname = str(angle) + '.png'\n",
    "\n",
    "                    plt.savefig(fname, dpi=120, format='png', bbox_inches='tight')\n",
    "                    images.append(imageio.imread(fname))\n",
    "                    #os.remove(fname)\n",
    "                imageio.mimsave(path_to_save, images)\n",
    "                plt.close()\n",
    "\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "                \n",
    "class ShowResult:\n",
    "  \n",
    "    def mask_preprocessing(self, mask):\n",
    "        \"\"\"\n",
    "        Test.\n",
    "        \"\"\"\n",
    "        # removing all the ones in the tensor --> using cpu --> removing the tensor from its computational graph --> tensor to numpy conversion \n",
    "        \n",
    "        print(mask.shape)\n",
    "        mask_crop1 = mask[0,0,:,:,:]\n",
    "        mask_crop2 = mask[0,1,:,:,:]\n",
    "        mask_crop3 = mask[0,2,:,:,:]\n",
    "        \n",
    "        mask_WT = montage(mask_crop1)\n",
    "        mask_TC = montage(mask_crop2)\n",
    "        mask_ET = montage(mask_crop3)\n",
    "\n",
    "        return mask_WT, mask_TC, mask_ET\n",
    "        \n",
    "\n",
    "    def image_preprocessing(self, image):\n",
    "        \"\"\"\n",
    "        Returns image flair as mask for overlaping gt and predictions.\n",
    "        \"\"\"\n",
    "        image = image.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        # image = np.moveaxis(image, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "        \n",
    "        img_crop = image[0, :,:,:]\n",
    "        flair_img = montage(img_crop)\n",
    "        \n",
    "        return flair_img\n",
    "    \n",
    "    def plot(self, image, ground_truth, prediction):\n",
    "        image = self.image_preprocessing(image)\n",
    "        gt_mask_WT, gt_mask_TC, gt_mask_ET = self.mask_preprocessing(ground_truth)\n",
    "        pr_mask_WT, pr_mask_TC, pr_mask_ET = self.mask_preprocessing(prediction)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize = (35, 30))\n",
    "    \n",
    "        [ax.axis(\"off\") for ax in axes]\n",
    "        axes[0].set_title(\"Ground Truth\", fontsize=35, weight='bold')\n",
    "        axes[0].imshow(image, cmap ='bone')\n",
    "        axes[0].imshow(np.ma.masked_where(gt_mask_WT == False, gt_mask_WT),\n",
    "                  cmap='summer', alpha=0.6)\n",
    "        axes[0].imshow(np.ma.masked_where(gt_mask_TC == False, gt_mask_TC),\n",
    "                  cmap='rainbow', alpha=0.6)\n",
    "        axes[0].imshow(np.ma.masked_where(gt_mask_ET == False, gt_mask_ET),\n",
    "                  cmap='Wistia', alpha=0.6)\n",
    "\n",
    "                  \n",
    "\n",
    "        axes[1].set_title(\"Prediction\", fontsize=35, weight='bold')\n",
    "        axes[1].imshow(image, cmap ='bone')\n",
    "        axes[1].imshow(np.ma.masked_where(pr_mask_WT == False, pr_mask_WT),\n",
    "                   cmap='summer', alpha=0.6)\n",
    "        axes[1].imshow(np.ma.masked_where(pr_mask_TC == False, pr_mask_TC),\n",
    "                   cmap='rainbow', alpha=0.6)\n",
    "        axes[1].imshow(np.ma.masked_where(pr_mask_ET == False, pr_mask_ET),\n",
    "                  cmap='Wistia', alpha=0.6)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "def merging_two_gif(path1: str, path2: str, name_to_save: str):\n",
    "    \"\"\"\n",
    "    Merging GIFs side by side.\n",
    "    Parameters:\n",
    "        path1: path to gif with ground truth.\n",
    "        path2: path to gif with prediction.\n",
    "        name_to_save: name for saving new GIF.\n",
    "    \"\"\"\n",
    "    #Create reader object for the gif\n",
    "    gif1 = imageio.get_reader(path1)\n",
    "    gif2 = imageio.get_reader(path2)\n",
    "\n",
    "    #If they don't have the same number of frame take the shorter\n",
    "    number_of_frames = min(gif1.get_length(), gif2.get_length()) \n",
    "\n",
    "    #Create writer object\n",
    "    new_gif = imageio.get_writer(name_to_save)\n",
    "\n",
    "    for frame_number in range(number_of_frames):\n",
    "        img1 = gif1.get_next_data()\n",
    "        img2 = gif2.get_next_data()\n",
    "        #here is the magic\n",
    "        new_image = np.hstack((img1, img2))\n",
    "        new_gif.append_data(new_image)\n",
    "\n",
    "    gif1.close()\n",
    "    gif2.close()    \n",
    "    new_gif.close()\n",
    "    \n",
    "#merging_two_gif('BraTS20_Training_001_flair_3d.gif',\n",
    "#                'BraTS20_Training_001_flair_3d.gif', \n",
    "#                'result.gif')\n",
    "\n",
    "def get_all_csv_file(root: str) -> list:\n",
    "    \"\"\"Extraction all unique ids from file names.\"\"\"\n",
    "    ids = []\n",
    "    for dirname, _, filenames in os.walk(root):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(dirname, filename)\n",
    "            if path.endswith(\".csv\"):\n",
    "                ids.append(path) \n",
    "    ids = list(set(filter(None, ids)))\n",
    "    print(f\"Extracted {len(ids)} csv files.\")\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalConfig:\n",
    "    root_dir = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour'\n",
    "    train_root_dir = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData'\n",
    "    test_root_dir = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\test_df'\n",
    "    path_to_csv = 'tumourCSV.csv'\n",
    "    \n",
    "\n",
    "    # Define the directory where the model checkpoints are saved\n",
    "    \n",
    "    UNet_checkpoint_dir = r\"C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\UNet model\"\n",
    "    ResUNet_checkpoint_dir =  r\"C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\ResUNet model\"\n",
    "    Att_checkpoint_dir = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\AttUNet model'\n",
    "\n",
    "    train_logs_path = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\UNet model\\train_log.csv'\n",
    "    ResUNet_train_logs_path = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\ResUNet model\\train_log.csv'\n",
    "    AttUNet_train_logs_path = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\AttUNet model\\train_log.csv'\n",
    "\n",
    "    \n",
    "    seed = 55\n",
    "    \n",
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "config = GlobalConfig()\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 3D scatterplot of the brain using Plotly (Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageReader:\n",
    "    def __init__(self, root:str, img_size:int=256, normalize:bool=False, single_class:bool=False):\n",
    "        pad_size = 256 if img_size > 256 else 224\n",
    "        self.resize = A.Compose(\n",
    "            [\n",
    "                A.PadIfNeeded(min_height=pad_size, min_width=pad_size, value=0),\n",
    "                A.Resize(img_size, img_size)\n",
    "            ]\n",
    "        )\n",
    "        self.normalize=normalize\n",
    "        self.single_class=single_class\n",
    "        self.root=root\n",
    "        \n",
    "    def read_file(self, path:str) -> dict:\n",
    "        scan_type = path.split('_')[-1]\n",
    "        raw_image = nib.load(path).get_fdata()\n",
    "        raw_mask = nib.load(path.replace(scan_type, 'seg.nii')).get_fdata()\n",
    "        processed_frames, processed_masks = [], []\n",
    "        for frame_idx in range(raw_image.shape[2]):\n",
    "            frame = raw_image[:, :, frame_idx]\n",
    "            mask = raw_mask[:, :, frame_idx]\n",
    "            if self.normalize:\n",
    "                if frame.max() > 0:\n",
    "                    frame = frame/frame.max()\n",
    "                frame = frame.astype(np.float32)\n",
    "            else:\n",
    "                frame = frame.astype(np.uint8)\n",
    "            resized = self.resize(image=frame, mask=mask)\n",
    "            processed_frames.append(resized['image'])\n",
    "            processed_masks.append(1*(resized['mask'] > 0) if self.single_class else resized['mask'])\n",
    "        return {\n",
    "            'scan': np.stack(processed_frames, 0),\n",
    "            'segmentation': np.stack(processed_masks, 0),\n",
    "            'orig_shape': raw_image.shape\n",
    "        }\n",
    "    \n",
    "    def load_patient_scan(self, idx:int, scan_type:str='flair') -> dict:\n",
    "        patient_id = str(1).zfill(3) \n",
    "        scan_filename = f'{self.root}/BraTS20_Training_{patient_id}/BraTS20_Training_{patient_id}_{scan_type}.nii'\n",
    "        return self.read_file(scan_filename)\n",
    "    \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly\n",
    "\n",
    "\n",
    "def generate_3d_scatter(\n",
    "    x:np.array, y:np.array, z:np.array, colors:np.array,\n",
    "    size:int=3, opacity:float=0.2, scale:str='Teal',\n",
    "    hover:str='skip', name:str='MRI'\n",
    ") -> go.Scatter3d:\n",
    "    return go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        mode='markers', hoverinfo=hover,\n",
    "        marker = dict(\n",
    "            size=size, opacity=opacity,\n",
    "            color=colors, colorscale=scale\n",
    "        ),\n",
    "        name=name\n",
    "    )\n",
    "\n",
    "\n",
    "class ImageViewer3d():\n",
    "    def __init__(\n",
    "        self, reader:ImageReader, mri_downsample:int=10, mri_colorscale:str='Ice'\n",
    "    ) -> None:\n",
    "        self.reader = reader\n",
    "        self.mri_downsample = mri_downsample\n",
    "        self.mri_colorscale = mri_colorscale\n",
    "\n",
    "    def load_clean_mri(self, image:np.array, orig_dim:int) -> dict:\n",
    "        shape_offset = image.shape[1]/orig_dim\n",
    "        z, x, y = (image > 0).nonzero()\n",
    "        # only (1/mri_downsample) is sampled for the resulting image\n",
    "        x, y, z = x[::self.mri_downsample], y[::self.mri_downsample], z[::self.mri_downsample]\n",
    "        colors = image[z, x, y]\n",
    "        return dict(x=x/shape_offset, y=y/shape_offset, z=z, colors=colors)\n",
    "    def load_tumor_segmentation(self, image:np.array, orig_dim:int) -> dict:\n",
    "        tumors = {}\n",
    "        shape_offset = image.shape[1]/orig_dim\n",
    "        # 1/1, 1/3 si 1/5 pixeli pentru clasele tumorii  1(nucleu necrotic), 2(edem) si 4(tumoare de amplificare)\n",
    "        sampling = {\n",
    "            1: 1, 2: 3, 4: 5\n",
    "        }\n",
    "        for class_idx in sampling:\n",
    "            z, x, y = (image == class_idx).nonzero()\n",
    "            x, y, z = x[::sampling[class_idx]], y[::sampling[class_idx]], z[::sampling[class_idx]]\n",
    "            tumors[class_idx] = dict(\n",
    "                x=x/shape_offset, y=y/shape_offset, z=z,\n",
    "                colors=class_idx/4\n",
    "            )\n",
    "        return tumors\n",
    "    def collect_patient_data(self, scan:dict) -> tuple:\n",
    "        clean_mri = self.load_clean_mri(scan['scan'], scan['orig_shape'][0])\n",
    "        tumors = self.load_tumor_segmentation(scan['segmentation'], scan['orig_shape'][0])\n",
    "        markers_created = clean_mri['x'].shape[0] + sum(tumors[class_idx]['x'].shape[0] for class_idx in tumors)\n",
    "        return [\n",
    "            generate_3d_scatter(**clean_mri, scale=self.mri_colorscale, opacity=0.3, hover='skip', name='Brain MRI'),\n",
    "            generate_3d_scatter(**tumors[1], opacity=0.90, hover='all', name='Necrotic tumor core'),\n",
    "            generate_3d_scatter(**tumors[2], opacity=0.05, hover='all', name='Peritumoral invaded tissue'),\n",
    "            generate_3d_scatter(**tumors[4], opacity=0.30, hover='all', name='GD-enhancing tumor'),\n",
    "        ], markers_created\n",
    "    \n",
    "    def get_3d_scan(self, patient_idx:int, scan_type:str='flair') -> go.Figure:\n",
    "        scan = self.reader.load_patient_scan(patient_idx, scan_type)\n",
    "        data, num_markers = self.collect_patient_data(scan)\n",
    "        fig = go.Figure(data=data)\n",
    "        fig.update_layout(\n",
    "            title=f\"[Patient id:{patient_idx}] brain MRI scan ({num_markers} points)\",\n",
    "            legend_title=\"Pixel class (click to enable/disable)\",\n",
    "            font=dict(\n",
    "                family=\"Courier New, monospace\",\n",
    "                size=14,\n",
    "            ),\n",
    "            margin=dict(\n",
    "                l=0,r=0,b=0,t=30\n",
    "            ),\n",
    "            legend=dict(itemsizing='constant')\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "# tumour visualization time starts(tv0)\n",
    "tv0 = time.time() \n",
    "reader = ImageReader(config.train_root_dir, img_size=128, normalize=True, single_class=False)\n",
    "viewer = ImageViewer3d(reader, mri_downsample=25)\n",
    "\n",
    "fig = viewer.get_3d_scan(100, 'flair')\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the pretrained model exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exist(checkpoint_dir):\n",
    "        # Get a list of all files in the checkpoint directory\n",
    "        all_files = os.listdir(checkpoint_dir)\n",
    "\n",
    "        # Filter the files to get only the model checkpoint files\n",
    "        model_checkpoint_files = [file for file in all_files if file.startswith(\"last_epoch_model\")]\n",
    "        \n",
    "        if model_checkpoint_files:\n",
    "\n",
    "            sorted_file_names = sorted(model_checkpoint_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "            \n",
    "            # Get the latest model checkpoint file\n",
    "            latest_checkpoint_file = sorted_file_names[-1]\n",
    "            \n",
    "\n",
    "            # Construct the full path to the latest model checkpoint\n",
    "            pretrained_model_path = os.path.join(checkpoint_dir, latest_checkpoint_file)\n",
    "            \n",
    "            return pretrained_model_path\n",
    "        else:\n",
    "            pretrained_model_path = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two CSV files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_info_df = pd.read_csv(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\\survival_info.csv')\n",
    "name_mapping_df = pd.read_csv(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\\name_mapping.csv')\n",
    "\n",
    "name_mapping_df.rename({'BraTS_2020_subject_ID': 'Brats20ID'}, axis=1, inplace=True) \n",
    "\n",
    "\n",
    "df = survival_info_df.merge(name_mapping_df, on=\"Brats20ID\", how=\"right\")\n",
    "\n",
    "# renaming & merging into one dataframe\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the path to the Brain Tumour Segmentation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for _, row  in df.iterrows():  # iterating through each row\n",
    "    \n",
    "    id_ = row['Brats20ID']      # column brats20ID\n",
    "    phase = id_.split(\"_\")[-2]\n",
    "    if phase == 'Training':\n",
    "\n",
    "        path = os.path.join(config.train_root_dir, id_)\n",
    "    else:\n",
    "        print(phase)\n",
    "        path = os.path.join(config.test_root_dir, id_)\n",
    "    paths.append(path)\n",
    "    \n",
    "df['path'] = paths\n",
    "\n",
    "# Drop index 355 due to unavailable and missing data\n",
    "df = df.loc[df['Brats20ID'] != 'BraTS20_Training_355'].reset_index(drop=True)\n",
    "df.to_csv('tumourCSV.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified K fold splitting, which was experimented on but not used in the final work due to inferior results compared to train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = df.loc[df['Age'].notnull()].reset_index(drop=True)\n",
    "\n",
    "# train_data[\"Age_rank\"] =  train_data[\"Age\"] // 10 * 10\n",
    "\n",
    "# skf = StratifiedKFold(\n",
    "#     n_splits=7, random_state=config.seed, shuffle=True\n",
    "# )\n",
    "\n",
    "# # enumeratng all entries for defining the fold number \n",
    "# # assigning the fold number in increment order \n",
    "# for i, (train_index, val_index) in enumerate(\n",
    "#         skf.split(train_data, train_data[\"Age_rank\"])\n",
    "#         ):\n",
    "#         train_data.loc[val_index, \"fold\"] = i\n",
    "# train_df = train_data.loc[train_data['fold'] != 0].reset_index(drop=True)\n",
    "# val_df = train_data.loc[train_data['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "# # selecting the rows where the AGE col. is null --> test_df \n",
    "# test_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\n",
    "#print(\"train_df ->\", train_df_copy.shape, \"val_df ->\", val_df.shape, \"test_df ->\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train_test_split to obtain the training and validation and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy, test_df = train_test_split(df, test_size=0.30, random_state=10, shuffle=True)\n",
    "train_df_copy, test_df_copy = train_df_copy.reset_index(drop=True), test_df.reset_index(drop=True)\n",
    "\n",
    "print(train_df_copy.shape, test_df_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splitting of the data wasn't done for train , test &  validation data \n",
    "\n",
    "val_df = test_df_copy.iloc[:len(test_df_copy)*2//3]\n",
    "test_df = test_df_copy.iloc[len(test_df_copy)*2//3:]\n",
    "\n",
    "print(\"train_df ->\", train_df_copy.shape, \"val_df ->\", val_df.shape, \"test_df ->\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the new csv files based on the training, testing and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.to_csv(\"train_df.csv\", index=False)\n",
    "test_df.to_csv(\"test_df.csv\", index=False)\n",
    "val_df.to_csv(\"val_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentations(phase): \n",
    "    list_transforms = []\n",
    "    \n",
    "    # Does data augmentations & tranformation required for IMAGES & MASKS \n",
    "    # they include cropping, padding, flipping , rotating \n",
    "    list_trfms = Compose(list_transforms,  is_check_shapes=False)\n",
    "    return list_trfms\n",
    "\n",
    "\n",
    "def get_dataloader(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    path_to_csv: str,\n",
    "    phase: str,\n",
    "    fold: int = 0,\n",
    "    batch_size: int = 1,\n",
    "    num_workers: int = 0 \n",
    "    ):\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    train_df_copy, test_df = train_test_split(df, test_size=0.3, random_state=10, shuffle=True)\n",
    "    train_df_copy, test_df_copy = train_df_copy.reset_index(drop=True), test_df.reset_index(drop=True)\n",
    "    test_df = test_df_copy.iloc[len(test_df_copy)*2//3:].reset_index(drop=True)\n",
    "    val_df = test_df_copy.iloc[:len(test_df_copy)*2//3].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "\n",
    "    if phase != 'test':\n",
    "\n",
    "        \n",
    "    \n",
    "    # selection a particluar fold while calling the get_dataloader function \n",
    "        \n",
    "        '''Returns: dataloader for the model training'''\n",
    "        \n",
    "        if phase == \"train\" : \n",
    "            \n",
    "            df = train_df_copy\n",
    "        elif phase == \"valid\" :\n",
    "            \n",
    "            df = val_df\n",
    "        \n",
    "        dataset = dataset(df, phase)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        df = test_df\n",
    "        dataset = dataset(df, phase)\n",
    "    \"\"\"\n",
    "    DataLoader iteratively goes through every id in the df & gets all the individual tuples for individual ids & appends all of them \n",
    "    like this : \n",
    "    { id : ['BraTS20_Training_235'] ,\n",
    "      image : [] , \n",
    "      tensor : [] , \n",
    "    } \n",
    "    { id : ['BraTS20_Training_236'] ,\n",
    "      image : [] , \n",
    "      tensor : [] , \n",
    "    } \n",
    "    { id : ['BraTS20_Training_237'] ,\n",
    "      image : [] , \n",
    "      tensor : [] , \n",
    "    } \n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,   \n",
    "    )\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class BratsDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, phase: str=\"test\", is_resize: bool=True):\n",
    "        self.df = df\n",
    "        self.phase = phase\n",
    "        self.augmentations = get_augmentations(phase)\n",
    "        self.data_types = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\n",
    "        self.is_resize = is_resize\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0] \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # at a specified index ( idx ) select the value under 'Brats20ID' & asssign it to id_ \n",
    "        id_ = self.df.loc[idx, 'Brats20ID']\n",
    "        \n",
    "       \n",
    "        root_path = self.df.loc[self.df['Brats20ID'] == id_]['path'].values[0]\n",
    "        \n",
    "        # load all modalities\n",
    "        images = []\n",
    "        \n",
    "        for data_type in self.data_types:\n",
    "            img_path = os.path.join(root_path, id_ + data_type) \n",
    "            img = self.load_img(img_path)#.transpose(2, 0, 1)\n",
    "            \n",
    "            if self.is_resize:\n",
    "                img = self.resize(img)\n",
    "    \n",
    "            img = self.normalize(img)\n",
    "            images.append(img)\n",
    "            \n",
    "        img = np.stack(images)\n",
    "        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "        \n",
    "        # if self.phase != \"test\":\n",
    "        mask_path =  os.path.join(root_path, id_ + \"_seg.nii\")\n",
    "        mask = self.load_img(mask_path)\n",
    "        \n",
    "        if self.is_resize:\n",
    "            \n",
    "            mask = self.resize(mask)\n",
    "            \n",
    "        mask = self.preprocess_mask_labels(mask)\n",
    "        # setting the mask labels 1 , 2 , 4 for the mask file ( _seg.ii ) \n",
    "        \n",
    "\n",
    "        augmented = self.augmentations(image=img.astype(np.float32), \n",
    "                                        mask=mask.astype(np.float32))\n",
    "        # Several augmentations / transformations like flipping, rotating, padding will be applied to both the images \n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "\n",
    "    \n",
    "        return {\n",
    "            \"Id\": id_,\n",
    "            \"image\": img,\n",
    "            \"mask\": mask,\n",
    "            }\n",
    "        \n",
    "        \n",
    "    \n",
    "    def load_img(self, file_path):\n",
    "        data = nib.load(file_path)\n",
    "        data = np.asarray(data.dataobj)\n",
    "        return data\n",
    "    \n",
    "    def normalize(self, data: np.ndarray):\n",
    "        data_min = np.min(data)\n",
    "        # normalization = (each element - min element) / ( max - min ) \n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "    \n",
    "    def resize(self, data: np.ndarray):\n",
    "        \n",
    "        data = data[ 40:210, 40:210, 20:120]\n",
    "        # The selected indices do not remove the slices that contain the brain tumour\n",
    "        #40:210\n",
    "        #40:210\n",
    "        #20:120\n",
    "        return data\n",
    "    \n",
    "    def preprocess_mask_labels(self, mask: np.ndarray):\n",
    "\n",
    "        # whole tumour\n",
    "        mask_WT = mask.copy()\n",
    "        mask_WT[mask_WT == 1] = 1\n",
    "        mask_WT[mask_WT == 2] = 1\n",
    "        mask_WT[mask_WT == 4] = 1\n",
    "        # include all tumours \n",
    "\n",
    "        # NCR / NET - LABEL 1\n",
    "        mask_TC = mask.copy()\n",
    "        mask_TC[mask_TC == 1] = 1\n",
    "        mask_TC[mask_TC == 2] = 0\n",
    "        mask_TC[mask_TC == 4] = 1\n",
    "        # exclude 2 / 4 labelled tumour \n",
    "        \n",
    "        # ET - LABEL 4 \n",
    "        mask_ET = mask.copy()\n",
    "        mask_ET[mask_ET == 1] = 0\n",
    "        mask_ET[mask_ET == 2] = 0\n",
    "        mask_ET[mask_ET == 4] = 1\n",
    "        # exclude 2 / 1 labelled tumour \n",
    "        \n",
    "        # # ED - LABEL 2\n",
    "        # # mask_ED = mask.copy()\n",
    "        # # mask_ED[mask_ED == 1] = 0\n",
    "        # # mask_ED[mask_ED == 2] = 1\n",
    "        # # mask_ED[mask_ED == 4] = 0\n",
    "\n",
    "\n",
    "        # mask = np.stack([mask_WT, mask_TC, mask_ET, mask_ED])\n",
    "        mask = np.stack([mask_WT, mask_TC, mask_ET])\n",
    "        \n",
    "        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "\n",
    "        return mask  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='tumourCSV.csv', phase='train')\n",
    "len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='tumourCSV.csv', phase='test')\n",
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='tumourCSV.csv', phase='valid')\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Load one of the brain MRIs to visualize all the ground truth tumour segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = next(iter(dataloader))\n",
    "print('Shape: ', data['Id'], data['image'].shape, data['mask'].shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (20, 20))\n",
    "\n",
    "idx = 20\n",
    "ax[0].imshow(data['mask'][0,0,idx,:,:,], cmap ='bone')\n",
    "ax[1].imshow(data['mask'][0,1,idx,:,:,], cmap ='bone')\n",
    "ax[2].imshow(data['mask'][0,2,idx,:,:,], cmap ='bone')\n",
    "# batch size , channels , spatial dimensions\n",
    "# no.of images in a batch : channels : t1 , t2 , flair , weighted : dimensions\n",
    "\n",
    "\n",
    "img_tensor = data['image'].squeeze()[0].cpu().detach().numpy() \n",
    "\n",
    "mask_tensor = data['mask'].squeeze()[0].squeeze().cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num uniq Image values :\", len(np.unique(img_tensor, return_counts=True)[0]))\n",
    "print(\"Min/Max Image values:\", img_tensor.min(), img_tensor.max())\n",
    "print(\"Num uniq Mask values:\", np.unique(mask_tensor, return_counts=True))\n",
    "\n",
    "image = montage(img_tensor)\n",
    "mask = montage(mask_tensor)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (20, 20))\n",
    "ax.imshow(image, cmap ='bone')\n",
    "ax.imshow(np.ma.masked_where(mask == False, mask),\n",
    "           cmap='cool', alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Evaluation Metrics and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_metric(probabilities: torch.Tensor,\n",
    "                     truth: torch.Tensor, \n",
    "                     treshold: float = 0.5,\n",
    "                     eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Dice score for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: dice score aka f1.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0] \n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape) # shape of prediction and shape should be equal\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = 2.0 * (truth_ * prediction).sum()\n",
    "        union = truth_.sum() + prediction.sum()\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            scores.append((intersection + eps) / union)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def jaccard_coef_metric(probabilities: torch.Tensor,\n",
    "               truth: torch.Tensor,\n",
    "               treshold: float = 0.5,\n",
    "               eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Jaccard index for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: jaccard score aka iou.\"\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0]\n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = (prediction * truth_).sum()\n",
    "        union = (prediction.sum() + truth_.sum()) - intersection + eps\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            scores.append((intersection + eps) / union)\n",
    "    return np.mean(scores)\n",
    "            \n",
    "  \n",
    "\n",
    "class Meter:\n",
    "    '''factory for storing and updating iou and dice scores.'''\n",
    "    def __init__(self, treshold: float = 0.5):\n",
    "        self.threshold: float = treshold\n",
    "        self.dice_scores: list = []\n",
    "        self.iou_scores: list = []\n",
    "        self.haus_scores: list = []\n",
    "    \n",
    "    def update(self, logits: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Takes: logits from output model and targets,\n",
    "        calculates dice and iou scores, and stores them in lists.\n",
    "        calculates using the above declare functions \n",
    "        \"\"\"\n",
    "       \n",
    "        \n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        dice = dice_coef_metric(probs, targets, self.threshold)\n",
    "        \n",
    "        iou = jaccard_coef_metric(probs, targets, self.threshold)\n",
    "        \n",
    "        #haus = hausdorff_distance_metric(probs, targets)\n",
    "        #print(haus)\n",
    "        \n",
    "        # appending to the respective lists \n",
    "        self.dice_scores.append(dice)\n",
    "        self.iou_scores.append(iou)\n",
    "        #self.haus_scores.append(haus)\n",
    "        #print(self.haus_scores)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_metrics(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns: the average of the accumulated dice and iou scores.\n",
    "        \"\"\"\n",
    "        dice = np.mean(self.dice_scores)\n",
    "        iou = np.mean(self.iou_scores)\n",
    "        #haus = np.mean(self.haus_scores)\n",
    "        return dice, iou\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Calculate dice loss.\"\"\"\n",
    "    def __init__(self, eps: float = 1e-9):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,\n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        num = targets.size(0)\n",
    "        probability = torch.sigmoid(logits)\n",
    "        probability = probability.view(num, -1)\n",
    "        targets = targets.view(num, -1)\n",
    "        assert(probability.shape == targets.shape)\n",
    "        \n",
    "        intersection = 2.0 * (probability * targets).sum()\n",
    "        union = probability.sum() + targets.sum()\n",
    "        dice_score = (intersection + self.eps) / union\n",
    "        #print(\"intersection\", intersection, union, dice_score)\n",
    "        return 1.0 - dice_score\n",
    "        \n",
    "        \n",
    "class BCEDiceLoss(nn.Module):\n",
    "    \"\"\"Compute objective loss: BCE loss + DICE loss.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "        \n",
    "    def forward(self, \n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # logits are the images \n",
    "        # target are the masks \n",
    "        assert(logits.shape == targets.shape)\n",
    "        dice_loss = self.dice(logits, targets)\n",
    "        bce_loss = self.bce(logits, targets)\n",
    "        \n",
    "        # binary cross entropy loss & dice loss \n",
    "        return bce_loss + dice_loss\n",
    "    \n",
    "# helper functions for testing.  \n",
    "def dice_coef_metric_per_classes(probabilities: np.ndarray,\n",
    "                                    truth: np.ndarray,\n",
    "                                    treshold: float = 0.33,\n",
    "                                    eps: float = 1e-9,\n",
    "                                    classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Dice score for data batch and for each class i.e. 'WT', 'TC', 'ET'\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: model targets.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        classes: list with name classes.\n",
    "        Returns: dict with dice scores for each class.\n",
    "    \"\"\"\n",
    "    scores = {key: list() for key in classes}\n",
    "    num = probabilities.shape[0]\n",
    "    num_classes = probabilities.shape[1]\n",
    "    predictions = (probabilities >= treshold).astype(np.float32)\n",
    "    assert(predictions.shape == truth.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        for class_ in range(num_classes):\n",
    "            prediction = predictions[i][class_]\n",
    "            truth_ = truth[i][class_]\n",
    "            intersection = 2.0 * (truth_ * prediction).sum()\n",
    "            union = truth_.sum() + prediction.sum()\n",
    "            if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "                 scores[classes[class_]].append(1.0)\n",
    "            else:\n",
    "                scores[classes[class_]].append((intersection + eps) / union)\n",
    "                \n",
    "    return scores\n",
    "\n",
    "\n",
    "def jaccard_coef_metric_per_classes(probabilities: np.ndarray, # output of the model in an array format \n",
    "               truth: np.ndarray,# masks  \n",
    "               treshold: float = 0.33, # threshold to whether segment / not \n",
    "               eps: float = 1e-9, # smooth \n",
    "               classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Jaccard index for data batch and for each class.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: model targets.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        classes: list with name classes.\n",
    "        Returns: dict with jaccard scores for each class.\"\n",
    "    \"\"\"\n",
    "    scores = {key: list() for key in classes}\n",
    "    # storing all the jaccard coefficients in a list \n",
    "    \n",
    "    num = probabilities.shape[0]\n",
    "    \n",
    "    num_classes = probabilities.shape[1]\n",
    "    \n",
    "    # segmenting if prob > threshold .i.e. setting to float32 \n",
    "    predictions = (probabilities >= treshold).astype(np.float32)\n",
    "    \n",
    "    assert(predictions.shape == truth.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        for class_ in range(num_classes):\n",
    "            prediction = predictions[i][class_]\n",
    "            truth_ = truth[i][class_]\n",
    "            intersection = (prediction * truth_).sum()\n",
    "            union = (prediction.sum() + truth_.sum()) - intersection + eps\n",
    "            if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "                 scores[classes[class_]].append(1.0)\n",
    "            else:\n",
    "                scores[classes[class_]].append((intersection + eps) / union)\n",
    "\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Trainer Class to train the UNet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class Trainer():\n",
    "    \"\"\"\n",
    "    Factory for training proccess.\n",
    "    Args:\n",
    "        display_plot: if True - plot train history after each epoch.\n",
    "        net: neural network for mask prediction.\n",
    "        criterion: factory for calculating objective loss. i.e. bce loss + dice loss / others \n",
    "        optimizer: optimizer for weights updating. i.e. Adam \n",
    "        phases: list with train and validation phases.\n",
    "        dataloaders: dict with data loaders for train and val phases. i.e. DataLoader / dataloader \n",
    "        path_to_csv: path to csv file.\n",
    "        meter: factory for storing and updating metrics. -> return the jaccard coeff / dice loss \n",
    "        batch_size: data batch size for one step weights updating.\n",
    "        num_epochs: num weights updation for all data.\n",
    "        accumulation_steps: the number of steps after which the optimization step can be taken\n",
    "                    (https://www.kaggle.com/c/understanding_cloud_organization/discussion/105614).\n",
    "        lr: learning rate for optimizer.\n",
    "        scheduler: scheduler for control learning rate.\n",
    "        losses: dict for storing lists with losses for each phase.\n",
    "        jaccard_scores: dict for storing lists with jaccard scores for each phase.\n",
    "        dice_scores: dict for storing lists with dice scores for each phase.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 net: nn.Module,\n",
    "                 dataset: torch.utils.data.Dataset,\n",
    "                 criterion: nn.Module,\n",
    "                 lr: float,\n",
    "                 accumulation_steps: int,\n",
    "                 batch_size: int,\n",
    "                 fold: int,\n",
    "                 num_epochs: int,\n",
    "                 path_to_csv: str,\n",
    "                 model_type: str,\n",
    "                 display_plot: bool = True       \n",
    "                 \n",
    "                ):\n",
    "\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"device:\", self.device)\n",
    "        self.display_plot = display_plot\n",
    "        self.net = net\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = Adam(self.net.parameters(), lr=lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\",\n",
    "                                           patience=2, verbose=True)\n",
    "        self.accumulation_steps = accumulation_steps // batch_size\n",
    "        self.phases = [\"train\", \"valid\"]\n",
    "        self.num_epochs = num_epochs\n",
    "        self.model_type = model_type\n",
    "        self.epoch_value = self.check_epoch_number(self.model_type) \n",
    "        \n",
    "        \n",
    "        self.dataloaders = {\n",
    "            phase: get_dataloader(\n",
    "                dataset = dataset,\n",
    "                path_to_csv = path_to_csv,\n",
    "                phase = phase,\n",
    "                fold = fold,\n",
    "                batch_size = batch_size,\n",
    "                num_workers = 0\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "\n",
    "        self.best_loss = float(\"inf\")\n",
    "        \n",
    "        # calculating the list of losses for both train & validation phases \n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        \n",
    "        # calculating the dice scores for both train & validation phases \n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "        # calculating the jaccard scores for both train & validation phases\n",
    "        self.jaccard_scores = {phase: [] for phase in self.phases}\n",
    "\n",
    "        # calculating the time for both train & validation phases\n",
    "        self.time = {phase: [] for phase in self.phases}\n",
    "         \n",
    "    def _compute_loss_and_outputs(self,\n",
    "                                  images: torch.Tensor,\n",
    "                                  targets: torch.Tensor):\n",
    "        images = images.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "        \n",
    "        # making images predictions symmetric using logits  \n",
    "        logits = self.net(images)\n",
    "        \n",
    "        # calculating the loss bce loss / dice loss / jaccard loss / combined loss \n",
    "        # as defined calcluating the mean square error loss \n",
    "        loss = self.criterion(logits, targets)\n",
    "        return loss, logits\n",
    "        \n",
    "    def _do_epoch(self, epoch: int, phase: str):\n",
    "        start_time = time.time()\n",
    "        meter = Meter()\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        \n",
    "        total_batches = len(dataloader)\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Initialize tqdm progress bar\n",
    "        progress_bar = tqdm(dataloader, desc=f\"{phase} epoch: {epoch}\", unit=\"batch\", dynamic_ncols=True)\n",
    "\n",
    "        self.net.train() if phase == \"train\" else self.net.eval()\n",
    "\n",
    "        for itr, data_batch in enumerate(progress_bar):\n",
    "            images, targets = data_batch['image'], data_batch['mask']\n",
    "            \n",
    "            \n",
    "            # BCEDiceLoss & raw prediction( logits ) are calculated \n",
    "            \n",
    "            loss, logits = self._compute_loss_and_outputs(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                # Backpropagating the losses generated to train the Unet \n",
    "                loss.backward()\n",
    "                    \n",
    "                # if a certain no. is reached then all the gradient accumulated will be given to the optimizer & it gets trained\n",
    "                # after giving, gradient gets reset to 0 \n",
    "                if (itr + 1) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                        \n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": running_loss / (itr + 1)})  # Update loss in progress bar\n",
    "            meter.update(logits.detach().cpu(), targets.detach().cpu())\n",
    "\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        epoch_dice, epoch_iou = meter.get_metrics()\n",
    "\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(epoch_dice)\n",
    "        \n",
    "        self.jaccard_scores[phase].append(epoch_iou)\n",
    "        \n",
    "        \n",
    "        # self.haus_scores[phase].append(epoch_haus)\n",
    "        end_time = time.time()\n",
    "\n",
    "        total_time = end_time - start_time\n",
    "\n",
    "        total_time = round(total_time, 2)\n",
    "        self.time[phase].append(total_time)\n",
    "        return epoch_loss\n",
    "        \n",
    "    def run(self, check_path):\n",
    "        epoch = self.epoch_value\n",
    "        \n",
    "        for epoch in range(int(self.epoch_value) + 1, self.num_epochs):\n",
    "            self._do_epoch(epoch, \"train\")\n",
    "            with torch.no_grad():\n",
    "                val_loss = self._do_epoch(epoch, \"valid\")\n",
    "                print(f\"BCEDiceLoss for epoch {epoch} is : \" , val_loss ) \n",
    "                self.scheduler.step(val_loss)\n",
    "            if self.display_plot and epoch == self.num_epochs:\n",
    "                self._plot_train_history()\n",
    "                \n",
    "            if val_loss < self.best_loss:\n",
    "                print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n",
    "                self.best_loss = val_loss\n",
    "\n",
    "                checkpoint_dir = check_path\n",
    "\n",
    "                # Get a list of all files in the checkpoint directory\n",
    "                all_files = os.listdir(checkpoint_dir)\n",
    "                best_model_current = [file for file in all_files if file.startswith(\"best_model_\")]\n",
    "                for best_model in best_model_current:\n",
    "                    os.remove(checkpoint_dir + \"/\" + best_model)\n",
    "                torch.save(self.net, f\"{self.model_type}/best_model_{epoch}.pth\")\n",
    "            \n",
    "            if epoch % 1 == 0:\n",
    "                self._save_train_history(epoch)\n",
    "            print()\n",
    "        self._save_train_history()\n",
    "            \n",
    "    def _plot_train_history(self):\n",
    "        data = [self.losses, self.dice_scores, self.jaccard_scores]\n",
    "        colors = ['deepskyblue', \"crimson\"]\n",
    "        labels = [\n",
    "            f\"\"\"\n",
    "            train loss {self.losses['train'][-1]}\n",
    "            val loss {self.losses['val'][-1]}\n",
    "            \"\"\",\n",
    "            \n",
    "            f\"\"\"\n",
    "            train dice score {self.dice_scores['train'][-1]}\n",
    "            val dice score {self.dice_scores['val'][-1]} \n",
    "            \"\"\", \n",
    "                  \n",
    "            f\"\"\"\n",
    "            train jaccard score {self.jaccard_scores['train'][-1]}\n",
    "            val jaccard score {self.jaccard_scores['val'][-1]}\n",
    "            \"\"\"\n",
    "        ]\n",
    "        \n",
    "        clear_output(True)\n",
    "\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(8, 10))\n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.plot(data[i]['val'], c=colors[0], label=\"val\")\n",
    "            ax.plot(data[i]['train'], c=colors[-1], label=\"train\")\n",
    "            ax.set_title(labels[i])\n",
    "            ax.legend(loc=\"upper right\")\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "    def load_pretrain_model(self,\n",
    "                             state_path: str):\n",
    "        \n",
    "        pretrain = torch.load(state_path)\n",
    "        self.net.load_state_dict(pretrain.state_dict())\n",
    "        print(\"Pretrain model loaded\")\n",
    "\n",
    "    def check_epoch_number(self, checkpoint_dir):\n",
    "        value_of_hash = 0\n",
    "        # Get a list of all files in the checkpoint directory\n",
    "        all_files = os.listdir(checkpoint_dir)\n",
    "\n",
    "        # Filter the files to get only the model checkpoint files\n",
    "        model_checkpoint_files = [file for file in all_files if file.startswith(\"last_epoch_model\")]\n",
    "        \n",
    "        # Sort the model checkpoint files based on their names (assuming they contain the epoch number)\n",
    "        \n",
    "        if model_checkpoint_files:\n",
    "\n",
    "            sorted_file_names = sorted(model_checkpoint_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "            \n",
    "            # Get the latest model checkpoint file\n",
    "            latest_checkpoint_file = sorted_file_names[-1]\n",
    "            \n",
    "\n",
    "            # Construct the full path to the latest model checkpoint\n",
    "            pretrained_model_path = os.path.join(checkpoint_dir, latest_checkpoint_file)\n",
    "            latest = pretrained_model_path.split(\"_\")\n",
    "            value_of_hash = latest[-1].split(\".\")[0]\n",
    "            return value_of_hash\n",
    "        else:\n",
    "            return value_of_hash\n",
    "        \n",
    "    def _save_train_history(self, epoch):\n",
    "        \"\"\"writing model weights and training logs to files.\"\"\"\n",
    "        torch.save(self.net,\n",
    "                   f\"{self.model_type}\\last_epoch_model_{epoch}.pth\")\n",
    "\n",
    "        logs_ = [self.losses, self.dice_scores, self.jaccard_scores, self.time]\n",
    "        \n",
    "        log_names_ = [\"_loss\", \"_dice\", \"_jaccard\", \"_time\"]\n",
    "        logs = [logs_[i][key] for i in list(range(len(logs_)))\n",
    "                         for key in logs_[i]]\n",
    "        log_names = [key+log_names_[i] \n",
    "                     for i in list(range(len(logs_))) \n",
    "                     for key in logs_[i]\n",
    "                    ]\n",
    "        pd.DataFrame(\n",
    "            dict(zip(log_names, logs))\n",
    "        ).to_csv(f\"{self.model_type}/train_log.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Defining the UNet models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):  # Each layer has two convolutions\n",
    "    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_groups=8):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            # Convlution set one \n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm3d(out_channels),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Convlution set two \n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm3d(out_channels),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "            \n",
    "          )\n",
    "\n",
    "    def forward(self,x): # Move forward will always go through 2 convolutional layers\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class Down(nn.Module): # Move downwards \n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool3d(2, 2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # max pooling 3d + doubleConv \n",
    "        return self.encoder(x)\n",
    "\n",
    "    \n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "            \n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet3d(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        # extracting the features by incrementally multiplying the no.of channels \n",
    "        self.conv = DoubleConv(in_channels, n_channels) #64\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels) #64,128\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels) #128, 256\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels) #256, 512\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels) #512, 512\n",
    "\n",
    "        self.dec1 = Up(16 * n_channels, 4 * n_channels) # 512+512, 256\n",
    "        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n",
    "        self.dec3 = Up(4 * n_channels, n_channels)\n",
    "        self.dec4 = Up(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "        \n",
    "        \"\"\"\n",
    "        After a series of either Upsampling / 3d Transpose\n",
    "        a segmented image of the input image is generated \n",
    "        & returned \n",
    "        \"\"\"\n",
    "        #print(mask.shape)\n",
    "        return mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet3d(in_channels=4, n_classes=3, n_channels=24).to('cuda')\n",
    "\n",
    "\n",
    "trainer = Trainer(net=model,\n",
    "                  dataset=BratsDataset,\n",
    "                  criterion=BCEDiceLoss(),\n",
    "                  lr=5e-4,\n",
    "                  accumulation_steps=4,\n",
    "                  batch_size=1,\n",
    "                  fold=0,\n",
    "                  num_epochs=200,\n",
    "                  path_to_csv = config.path_to_csv,\n",
    "                  model_type = config.UNet_checkpoint_dir\n",
    "                  )\n",
    "\n",
    "\n",
    "\n",
    "if check_exist(config.UNet_checkpoint_dir) is not None:\n",
    "    trainer.load_pretrain_model(check_exist(config.UNet_checkpoint_dir))\n",
    "    \n",
    "    # if need - load the logs.      \n",
    "    train_logs = pd.read_csv(config.train_logs_path)\n",
    "    trainer.losses[\"train\"] =  train_logs.loc[:, \"train_loss\"].to_list()\n",
    "    trainer.losses[\"valid\"] =  train_logs.loc[:, \"valid_loss\"].to_list()\n",
    "    trainer.dice_scores[\"train\"] = train_logs.loc[:, \"train_dice\"].to_list()\n",
    "    trainer.dice_scores[\"valid\"] = train_logs.loc[:, \"valid_dice\"].to_list()\n",
    "    trainer.jaccard_scores[\"train\"] = train_logs.loc[:, \"train_jaccard\"].to_list()\n",
    "    trainer.jaccard_scores[\"valid\"] = train_logs.loc[:, \"valid_jaccard\"].to_list()\n",
    "    trainer.time[\"train\"] = train_logs.loc[:, \"train_time\"].to_list()\n",
    "    trainer.time[\"valid\"] = train_logs.loc[:, \"valid_time\"].to_list()\n",
    "\n",
    "\n",
    "\n",
    "trainer.run(config.UNet_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResUNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):  # Each layer has two convolutions\n",
    "    \"\"\"(Conv3D -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_groups=8):\n",
    "        super().__init__()\n",
    "        self.residual_block = nn.Sequential(\n",
    "            # Convlution set one \n",
    "            # nn.BatchNorm3d(in_channels),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            #\n",
    "            # Convlution set two \n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            # nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            #\n",
    "          )\n",
    "        \n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "\n",
    "    def forward(self,x): # Move forward will always go through 2 convolutional layers\n",
    "        s = x\n",
    "        s = self.conv(s)\n",
    "        x = self.residual_block(x)\n",
    "        y = x + s\n",
    "        return y\n",
    "\n",
    "    \n",
    "class Down(nn.Module): # Move downwards \n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool3d(2, 2),\n",
    "            ResBlock(in_channels, out_channels)\n",
    "            \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # max pooling 3d + doubleConv \n",
    "        return self.encoder(x)\n",
    "\n",
    "    \n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "            \n",
    "        self.conv = ResBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size = 1)\n",
    "                                  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class FirstLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_groups = 8):\n",
    "        super().__init__()\n",
    "        self.residual_block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            # # Convlution set two \n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.conv(x)\n",
    "        x = self.residual_block(x)   \n",
    "        y = x + s\n",
    "        return y\n",
    "\n",
    "\n",
    "class ResUNet3d(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        # extracting the features by incrementally multiplying the no.of channels \n",
    "        self.conv = FirstLayer(in_channels, n_channels)\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels)\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n",
    "        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n",
    "        self.dec3 = Up(4 * n_channels, n_channels)\n",
    "        self.dec4 = Up(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "        \n",
    "        return mask\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the ResUNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ResUNet3d(in_channels=4, n_classes=3, n_channels=24).to('cuda')\n",
    "trainer = Trainer(net=model2,\n",
    "                  dataset=BratsDataset,\n",
    "                  criterion=BCEDiceLoss(),\n",
    "                  lr=5e-4,\n",
    "                  accumulation_steps=4,\n",
    "                  batch_size=1,\n",
    "                  fold=0,\n",
    "                  num_epochs=200,\n",
    "                  path_to_csv = config.path_to_csv,\n",
    "                  model_type = config.ResUNet_checkpoint_dir\n",
    "                  )\n",
    "\n",
    "if config.ResUNet_checkpoint_dir is not None:\n",
    "    trainer.load_pretrain_model(check_exist(config.ResUNet_checkpoint_dir))\n",
    "    \n",
    "    # if need - load the logs.      \n",
    "    train_logs = pd.read_csv(config.ResUNet_train_logs_path)\n",
    "    trainer.losses[\"train\"] =  train_logs.loc[:, \"train_loss\"].to_list()\n",
    "    trainer.losses[\"valid\"] =  train_logs.loc[:, \"valid_loss\"].to_list()\n",
    "    trainer.dice_scores[\"train\"] = train_logs.loc[:, \"train_dice\"].to_list()\n",
    "    trainer.dice_scores[\"valid\"] = train_logs.loc[:, \"valid_dice\"].to_list()\n",
    "    trainer.jaccard_scores[\"train\"] = train_logs.loc[:, \"train_jaccard\"].to_list()\n",
    "    trainer.jaccard_scores[\"valid\"] = train_logs.loc[:, \"valid_jaccard\"].to_list()\n",
    "    trainer.time[\"train\"] = train_logs.loc[:, \"train_time\"].to_list()\n",
    "    trainer.time[\"valid\"] = train_logs.loc[:, \"valid_time\"].to_list()\n",
    "\n",
    "trainer.run(config.ResUNet_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AttUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, ch, ratio=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
    "        self.ratio = ratio\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.channel = ch\n",
    "       \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv3d(self.channel, self.channel // self.ratio, kernel_size=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(self.channel // self.ratio, self.channel, kernel_size=1, bias=False)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x1 = self.avg_pool(x)\n",
    "        \n",
    "        \n",
    "        x1 = self.mlp(x1) \n",
    "        x2 = self.max_pool(x)\n",
    "        x2 = self.mlp(x2)\n",
    "\n",
    "        feats = x1 + x2\n",
    "        feats = self.sigmoid(feats)\n",
    "        refined_feats = x * feats\n",
    "        return refined_feats\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, ch, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(2, ch, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        feats = self.sigmoid(x)\n",
    "        refined_feats = x* feats\n",
    "        return refined_feats\n",
    "    \n",
    "    \n",
    "class cbam(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.ca = ChannelAttention(channel)\n",
    "        \n",
    "        self.sa = SpatialAttention(channel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ca(x)\n",
    "        \n",
    "        x = self.sa(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# https://idiotdeveloper.com/attention-unet-in-pytorch/\n",
    "class attention_gate(nn.Module):\n",
    "    def __init__(self, in_c, out_c): \n",
    "        super().__init__()\n",
    "        \n",
    "        self.Wg = nn.Sequential(\n",
    "            nn.Conv3d(in_c, out_c, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm3d(out_c)\n",
    "        )\n",
    "        self.Ws = nn.Sequential(\n",
    "            \n",
    "            nn.Conv3d(in_c, out_c, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm3d(out_c)\n",
    "            \n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv3d(out_c, out_c, kernel_size=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    " \n",
    "    def forward(self, g, s):\n",
    "        \n",
    "        Wg = self.Wg(g) #from attention gate\n",
    "        \n",
    "       \n",
    "        Ws = self.Ws(s) #from skip connection\n",
    "        \n",
    "        out = self.relu(Wg + Ws)\n",
    "        \n",
    "        out = self.output(out)\n",
    "        \n",
    "        return out * Ws\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AttUNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AttUp(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "            \n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        \n",
    "        self.num_channels = in_channels //2\n",
    "        self.cbam_module =  cbam(self.num_channels)\n",
    "        self.attention_gate = attention_gate(self.num_channels, self.num_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n",
    "        \n",
    "        x2 = self.cbam_module(x2)\n",
    "        \n",
    "        x2 = self.attention_gate(x1,x2)\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "    \n",
    "class Down(nn.Module): # Move downwards \n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool3d(2, 2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # max pooling 3d + doubleConv \n",
    "        return self.encoder(x)\n",
    "    \n",
    "class AttUNet3d(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        # extracting the features by incrementally multiplying the no.of channels \n",
    "        self.conv = DoubleConv(in_channels, n_channels)\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels)\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.dec1 = AttUp(16 * n_channels, 4 * n_channels)\n",
    "        self.dec2 = AttUp(8* n_channels, 2 * n_channels)\n",
    "        self.dec3 = AttUp(4 * n_channels, n_channels)\n",
    "        self.dec4 = AttUp(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x) \n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        \n",
    "        #Bridge\n",
    "        \n",
    "        x5 = self.enc4(x4)\n",
    "        \n",
    "        #Decoder\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "        \n",
    "        return mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the AttUNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = AttUNet3d(in_channels=4, n_classes=3, n_channels=24).to('cuda')\n",
    "\n",
    "trainer = Trainer(net=model3,\n",
    "                  dataset=BratsDataset,\n",
    "                  criterion=BCEDiceLoss(),\n",
    "                  lr=5e-4,\n",
    "                  accumulation_steps=4,\n",
    "                  batch_size=1,\n",
    "                  fold=0,\n",
    "                  num_epochs=100,\n",
    "                  path_to_csv = config.path_to_csv,\n",
    "                  model_type = config.Att_checkpoint_dir\n",
    "                  )\n",
    "\n",
    "if config.Att_checkpoint_dir is not None:\n",
    "    trainer.load_pretrain_model(check_exist(config.Att_checkpoint_dir))\n",
    "    \n",
    "    # if need - load the logs.      \n",
    "    train_logs = pd.read_csv(config.AttUNet_train_logs_path)\n",
    "    trainer.losses[\"train\"] =  train_logs.loc[:, \"train_loss\"].to_list()\n",
    "    trainer.losses[\"valid\"] =  train_logs.loc[:, \"valid_loss\"].to_list()\n",
    "    trainer.dice_scores[\"train\"] = train_logs.loc[:, \"train_dice\"].to_list()\n",
    "    trainer.dice_scores[\"valid\"] = train_logs.loc[:, \"valid_dice\"].to_list()\n",
    "    trainer.jaccard_scores[\"train\"] = train_logs.loc[:, \"train_jaccard\"].to_list()\n",
    "    trainer.jaccard_scores[\"valid\"] = train_logs.loc[:, \"valid_jaccard\"].to_list()\n",
    "    trainer.time[\"train\"] = train_logs.loc[:, \"train_time\"].to_list()\n",
    "    trainer.time[\"valid\"] = train_logs.loc[:, \"valid_time\"].to_list()\n",
    "\n",
    "trainer.run(config.Att_checkpoint_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if get error two different devices, need to initiate all classes in init function, can't be in forward function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Testing and Validating Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models and put them into evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet = torch.load(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\UNet model\\best_model_79.pth')\n",
    "ResUNet = torch.load(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\ResUNet model\\best_model_93.pth')\n",
    "AttUNet = torch.load(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\AttUNet model\\best_model_74.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResUNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttUNet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='tumourCSV.csv', phase=\"valid\")\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the TP, FP, TN and FN scores for the pixel classification evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "gc.collect() \n",
    "def compute_metrics(model, dataloader, threshold=0.33):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    counter = 0  # Counter to keep track of the number of entries processed\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations to save memory\n",
    "        for data in dataloader:\n",
    "            \n",
    "            images, targets = data['image'], data['mask']\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            predictions = (probabilities >= threshold).float()\n",
    "\n",
    "            # Compute binary segmentation metrics\n",
    "            true_positives += torch.sum((predictions == 1) & (targets == 1)).item()\n",
    "            false_positives += torch.sum((predictions == 1) & (targets == 0)).item()\n",
    "            true_negatives += torch.sum((predictions == 0) & (targets == 0)).item()\n",
    "            false_negatives += torch.sum((predictions == 0) & (targets == 1)).item()\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            # Free memory by clearing intermediate variables\n",
    "            del images, targets, logits, probabilities, predictions\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return true_positives , false_positives , true_negatives , false_negatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(ax, tp, fp, tn, fn, title):\n",
    "    # Create confusion matrix array\n",
    "    confusion_matrix = np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "    # Set up labels for matrix\n",
    "    labels = ['True ', 'False ']\n",
    "\n",
    "    # Create color map\n",
    "    cmap = plt.cm.Blues\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cax = ax.matshow(confusion_matrix, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Add colorbar to the figure\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "\n",
    "    # Add labels to matrix cells\n",
    "    thresh = confusion_matrix.max() / 2.\n",
    "    for i, j in np.ndindex(confusion_matrix.shape):\n",
    "        ax.text(j, i, format(confusion_matrix[i, j], 'd'), horizontalalignment='center', color='white' if confusion_matrix[i, j] > thresh else 'black')\n",
    "\n",
    "    # Set tick labels\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    # Set axis labels\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric (tp,tn,fp,fn):\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp , fp , tn , fn  = compute_metrics(UNet, val_dataloader, threshold=0.33)\n",
    "resTP, resFP, resTN, resFN = compute_metrics(ResUNet, val_dataloader, threshold=0.33)\n",
    "attTP, attFP, attTN, attFN = compute_metrics(AttUNet, val_dataloader, threshold=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots in a single row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot the confusion matrices\n",
    "plot_confusion_matrix(axes[0], tp, fp, tn, fn, \"Confusion Matrix UNet (Validation)\")\n",
    "plot_confusion_matrix(axes[1], resTP, resFP, resTN, resFN, \"Confusion Matrix ResUNet (Validation)\")\n",
    "plot_confusion_matrix(axes[2], attTP, attFP, attTN, attFN, \"Confusion Matrix AttUNet (Validation)\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNetMetric = metric(tp, tn, fp, fn)\n",
    "ResUNetMetric = metric(resTP, resTN, resFP, resFN)\n",
    "AttUNetMetric = metric(attTP, attTN, attFP, attFN)\n",
    "\n",
    "dictionary = {'UNet':UNetMetric,\n",
    "        'ResUNet':ResUNetMetric,\n",
    "        'AttUNet':AttUNetMetric\n",
    "        }\n",
    "df = pd.DataFrame(dictionary,['Validation Accuracy', 'Validation Precision', 'Validation Recall', 'Validation F1 Score'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performance Metrics (Validation)')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp , fp , tn , fn  = compute_metrics(UNet, test_dataloader, threshold=0.33)\n",
    "resTP, resFP, resTN, resFN = compute_metrics(ResUNet, test_dataloader, threshold=0.33)\n",
    "attTP, attFP, attTN, attFN = compute_metrics(AttUNet, test_dataloader, threshold=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots in a single row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot the confusion matrices\n",
    "plot_confusion_matrix(axes[0], tp, fp, tn, fn, \"Confusion Matrix UNet (Testing)\")\n",
    "plot_confusion_matrix(axes[1], resTP, resFP, resTN, resFN, \"Confusion Matrix ResUNet (Testing)\")\n",
    "plot_confusion_matrix(axes[2], attTP, attFP, attTN, attFN, \"Confusion Matrix AttUNet (Testing)\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNetMetric = metric(tp, tn, fp, fn)\n",
    "ResUNetMetric = metric(resTP, resTN, resFP, resFN)\n",
    "AttUNetMetric = metric(attTP, attTN, attFP, attFN)\n",
    "\n",
    "dictionary = {'UNet':UNetMetric,\n",
    "        'ResUNet':ResUNetMetric,\n",
    "        'AttUNet':AttUNetMetric\n",
    "        }\n",
    "df1 = pd.DataFrame(dictionary,['Testing Accuracy', 'Testing Precision', 'Testing Recall', 'Testing F1 Score'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performance Metrics (Testing)')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Scores per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def compute_metrics(model, dataloader, num_entries, threshold=0.33):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Counter to keep track of the number of entries processed\n",
    "    counter = 0  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if counter >= num_entries:\n",
    "                break  # Stop processing entries if the desired number is reached\n",
    "\n",
    "            images, targets = data['image'], data['mask']\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            prediction = (probabilities >= threshold).float()\n",
    "\n",
    "            prediction =  prediction.cpu()\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "            predictions.append(prediction)\n",
    "\n",
    "            model.zero_grad()\n",
    "            del images, targets, logits, probabilities, prediction\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    y_true = np.concatenate([targets.cpu() for data in dataloader for targets in data['mask']])\n",
    "    y_pred = np.concatenate([prediction.cpu() for data in dataloader for prediction in predictions])\n",
    "    \n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Compute classification report\n",
    "    class_names = ['Background', 'Tumor']\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "    # Return evaluation metrics, confusion matrix, and classification report\n",
    "    evaluation_results = {\n",
    "        'Confusion Matrix': cm,\n",
    "        'Classification Report': report\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = get_dataloader(BratsDataset, 'tumourCSV.csv', phase='valid')\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = get_dataloader(BratsDataset, 'tumourCSV.csv', phase='test')\n",
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining Time taken to train and validate per epoch during the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_data = pd.read_csv(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\UNet model\\train_log.csv')\n",
    "res_train_data = pd.read_csv(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\ResUNet model\\train_log.csv')\n",
    "att_train_data = pd.read_csv(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\AttUNet model\\train_log.csv')\n",
    "\n",
    "def gettime(train_data, model):\n",
    "    base_mean_tratime = train_data['train_time'].mean()\n",
    "    base_mean_valtime = train_data['valid_time'].mean() \n",
    "    \n",
    "    # Create a dictionary with the results\n",
    "    data = {\n",
    "        'Model': [model],\n",
    "        f'Training Time ({len(dataloader)} instances)': [f\"{base_mean_tratime: .2f} s\"],\n",
    "        f'Validation Time ({len(val_dataloader)} instances) ': [f\"{base_mean_valtime: .2f} s\"],\n",
    "    }\n",
    "    \n",
    "    # Convert the dictionary to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_time = pd.concat([gettime(base_train_data, \"UNet\"),gettime(res_train_data, \"ResUNet\"),gettime(att_train_data, \"AttUNet\")])\n",
    "\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphical Representations of Training vs Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotScoresindi(metric, model=['UNet', 'ResUNet', 'AttUNet']):\n",
    "\n",
    "    for i in model:\n",
    "        print(i)\n",
    "        train_data = pd.read_csv(rf'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\{i} model\\train_log.csv')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plotting training Dice scores\n",
    "        plt.plot(train_data[f'train_{metric}'], label=f'Training {metric}')\n",
    "\n",
    "        # Plotting validation Dice scores\n",
    "        plt.plot(train_data[f'valid_{metric}'], label=f'Validation {metric}')\n",
    "\n",
    "        # Adding titles and labels\n",
    "        plt.title(f'Training and Validation {metric} Scores for {i}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Dice Score')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plotScores(metric, models=['UNet', 'ResUNet', 'AttUNet']):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        train_data = pd.read_csv(rf'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\{model} model\\train_log.csv')\n",
    "        print(model, ' num epochs:', len(train_data))\n",
    "\n",
    "        # Plotting training Dice scores\n",
    "        plt.plot(train_data[f'train_{metric}'], label=f'Training {metric} ({model})')\n",
    "\n",
    "        # Plotting validation Dice scores\n",
    "        plt.plot(train_data[f'valid_{metric}'], label=f'Validation {metric} ({model})')\n",
    "\n",
    "    # Adding titles and labels\n",
    "    plt.title(f'Training and Validation {metric} Scores for {models}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of BCEDice Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScores('loss')\n",
    "plotScoresindi('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScores('dice')\n",
    "plotScoresindi('dice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScores('jaccard')\n",
    "plotScoresindi('jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Jaccard and Dice Scores per Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores_per_classes(model,          # model \n",
    "                               dataloader,     # tuple consisting of ( id , image tensor , mask tensor )\n",
    "                               classes):       # classes : WT , TC , ET \n",
    "    \"\"\"\n",
    "    Compute Dice and Jaccard coefficients for each class.\n",
    "    Params:\n",
    "        model: neural net for make predictions.\n",
    "        dataloader: dataset object to load data from.\n",
    "        classes: list with classes.\n",
    "        Returns: dictionaries with dice and jaccard coefficients for each class for each slice.\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dice_scores_per_classes = {key: list() for key in classes}\n",
    "    iou_scores_per_classes = {key: list() for key in classes}\n",
    "    haus_scores_per_classes = {key: list() for key in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            imgs, targets = data['image'], data['mask']\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            logits = model(imgs)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "            \n",
    "            # Now finding the overlap between the raw prediction i.e. logit & the mask i.e. target & finding the dice & iou scores \n",
    "            dice_scores = dice_coef_metric_per_classes(logits, targets)\n",
    "            iou_scores = jaccard_coef_metric_per_classes(logits, targets)\n",
    "            #haus_scores = hausdorff_distance_metric_per_class(logits, targets)\n",
    "             \n",
    "            # storing both dice & iou scores in the list declared \n",
    "            for key in dice_scores.keys():\n",
    "                dice_scores_per_classes[key].extend(dice_scores[key])\n",
    "\n",
    "            for key in iou_scores.keys():\n",
    "                iou_scores_per_classes[key].extend(iou_scores[key])\n",
    "\n",
    "            # for key in iou_scores.keys():\n",
    "            #     haus_scores_per_classes[key].extend(haus_scores[key])\n",
    "\n",
    "    return dice_scores_per_classes, iou_scores_per_classes\n",
    "\n",
    "def compute_scores_per_classes_mean(model,          \n",
    "                               dataloader,    \n",
    "                               classes):\n",
    "    \n",
    "    dice_scores_per_classes, iou_scores_per_classes = compute_scores_per_classes(model,          \n",
    "                               dataloader,    \n",
    "                               classes)\n",
    "    \n",
    "\n",
    "    dice_means = {key: np.mean(values) for key, values in dice_scores_per_classes.items()}\n",
    "    iou_means = {key: np.mean(values) for key, values in iou_scores_per_classes.items()}\n",
    "    \n",
    "    return dice_means, iou_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(model_metrics, model_name, type, ax=None):\n",
    "    colors = ['#35FCFF', '#FF355A', '#96C503', '#C5035B', '#28B463', '#35FFAF']\n",
    "    palette = sns.color_palette(colors, 6)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    sns.barplot(x=model_metrics.mean().index, y=model_metrics.mean(), palette=palette, ax=ax)\n",
    "    ax.set_xticklabels(model_metrics.columns, fontsize=14, rotation=15)\n",
    "    ax.set_title(f\"{model_name} Dice and Jaccard Coefficients from {type}\", fontsize=20)\n",
    "    \n",
    "    ax.set_xlabel(None, fontsize=16)\n",
    "    ax.set_ylabel('Dice Score', fontsize=16)\n",
    "\n",
    "    for idx, p in enumerate(ax.patches):\n",
    "        percentage = '{:.3f}'.format(model_metrics.mean().values[idx])\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.15\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax.annotate(percentage, (x, y), fontsize=15, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_per_classes, iou_scores_per_classes = compute_scores_per_classes(\n",
    "    UNet, val_dataloader, ['WT', 'TC', 'ET']\n",
    "    )\n",
    "dice_df = pd.DataFrame(dice_scores_per_classes)\n",
    "dice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "iou_df = pd.DataFrame(iou_scores_per_classes)\n",
    "iou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "val_metrics_df = pd.concat([dice_df, iou_df], axis=1, sort=True)\n",
    "\n",
    "                                      \n",
    "\n",
    "base_sample = val_metrics_df.round(6).sample(5)\n",
    "base_sample   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdice_scores_per_classes, resiou_scores_per_classes = compute_scores_per_classes(\n",
    "    ResUNet, val_dataloader, ['WT', 'TC', 'ET']\n",
    "    )\n",
    "\n",
    "resdice_df = pd.DataFrame(resdice_scores_per_classes)\n",
    "resdice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "resiou_df = pd.DataFrame(resiou_scores_per_classes)\n",
    "resiou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "resval_metrics_df = pd.concat([resdice_df, resiou_df], axis=1, sort=True)\n",
    "\n",
    "\n",
    "res_sample = resval_metrics_df.round(6).sample(5)\n",
    "res_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attdice_scores_per_classes, attiou_scores_per_classes = compute_scores_per_classes(\n",
    "    AttUNet, val_dataloader, ['WT', 'TC', 'ET']\n",
    "    )\n",
    "\n",
    "attdice_df = pd.DataFrame(attdice_scores_per_classes)\n",
    "attdice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "attiou_df = pd.DataFrame(attiou_scores_per_classes)\n",
    "attiou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "attval_metrics_df = pd.concat([attdice_df, attiou_df], axis=1, sort=True)\n",
    "\n",
    "                                      \n",
    "\n",
    "att_sample = attval_metrics_df.round(6).sample(5)\n",
    "att_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_avg =pd.DataFrame([np.mean(dice_df.values, axis =0).round(6), np.mean(resdice_df.values, axis =0).round(6), np.mean(attdice_df.values, axis =0).round(6)], index = ['UNet', 'ResUNet', 'AttUNet'], columns = dice_df.columns)\n",
    "jac_avg = pd.DataFrame([np.mean(iou_df.values, axis =0).round(6), np.mean(resiou_df.values, axis =0).round(6), np.mean(attiou_df.values, axis =0).round(6)], index = ['UNet', 'ResUNet', 'AttUNet'], columns = iou_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 3))\n",
    "\n",
    "# Plotting UNet metrics\n",
    "axs[0].axis('tight')\n",
    "axs[0].axis('off')\n",
    "axs[0].table(cellText=dice_avg.values, colLabels=dice_df.columns, cellLoc='center', loc='center', rowLabels = ['UNet', 'ResUNet', 'AttUNet'])\n",
    "axs[0].set_title('WT, TC, ET Scores for Validation Dataset')\n",
    "\n",
    "# Plotting ResUNet metrics\n",
    "axs[1].axis('tight')\n",
    "axs[1].axis('off')\n",
    "axs[1].table(cellText=jac_avg.values, colLabels=iou_df.columns, cellLoc='center', loc='center', rowLabels = ['UNet', 'ResUNet', 'AttUNet'])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(10, 20))\n",
    "\n",
    "# Plotting UNet metrics\n",
    "bar(val_metrics_df, \"UNet\", type='Validation', ax=axs[0])\n",
    "\n",
    "# Plotting ResUNet metrics\n",
    "bar(resval_metrics_df, \"ResUNet\", type='Validation',ax=axs[1])\n",
    "\n",
    "# Plotting AttUNet metrics\n",
    "bar(attval_metrics_df, \"AttUNet\", type='Validation',ax=axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_per_classes, iou_scores_per_classes = compute_scores_per_classes(\n",
    "    UNet, test_dataloader, ['WT', 'TC', 'ET']\n",
    "    )\n",
    "dice_df = pd.DataFrame(dice_scores_per_classes)\n",
    "dice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "iou_df = pd.DataFrame(iou_scores_per_classes)\n",
    "iou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "# CONCAT BOTH THE COLUMNS ALONG AXIS 1 & SORT THE TWO \n",
    "test_metrics_df = pd.concat([dice_df, iou_df], axis=1, sort=True)                         \n",
    "\n",
    "base_sample_test = test_metrics_df.round(6).head(5)\n",
    "base_sample_test     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdice_scores_per_classes, resiou_scores_per_classes = compute_scores_per_classes(\n",
    "    ResUNet, test_dataloader, ['WT', 'TC', 'ET']\n",
    "    )\n",
    "\n",
    "resdice_df = pd.DataFrame(resdice_scores_per_classes)\n",
    "resdice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "resiou_df = pd.DataFrame(resiou_scores_per_classes)\n",
    "resiou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "# CONCAT BOTH THE COLUMNS ALONG AXIS 1 & SORT THE TWO \n",
    "restest_metrics_df = pd.concat([resdice_df, resiou_df], axis=1, sort=True)\n",
    "\n",
    "res_sample_test = restest_metrics_df.round(6).sample(5)\n",
    "res_sample_test     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attdice_scores_per_classes, attiou_scores_per_classes = compute_scores_per_classes(\n",
    "    AttUNet, test_dataloader, ['WT', 'TC', 'ET']\n",
    "    )\n",
    "\n",
    "attdice_df = pd.DataFrame(attdice_scores_per_classes)\n",
    "attdice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "attiou_df = pd.DataFrame(attiou_scores_per_classes)\n",
    "attiou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "# CONCAT BOTH THE COLUMNS ALONG AXIS 1 & SORT THE TWO \n",
    "atttest_metrics_df = pd.concat([attdice_df, attiou_df], axis=1, sort=True)\n",
    "\n",
    "                                      \n",
    "\n",
    "att_sample_test = atttest_metrics_df.round(6).sample(5)\n",
    "att_sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dice_avg =pd.DataFrame([np.mean(dice_df.values, axis =0).round(6), np.mean(resdice_df.values, axis =0).round(6), np.mean(attdice_df.values, axis =0).round(6)], index = ['UNet', 'ResUNet', 'AttUNet'], columns = dice_df.columns)\n",
    "jac_avg = pd.DataFrame([np.mean(iou_df.values, axis =0).round(6), np.mean(resiou_df.values, axis =0).round(6), np.mean(attiou_df.values, axis =0).round(6)], index = ['UNet', 'ResUNet', 'AttUNet'], columns = iou_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 3))\n",
    "\n",
    "# Plotting UNet metrics\n",
    "axs[0].axis('tight')\n",
    "axs[0].axis('off')\n",
    "axs[0].table(cellText=dice_avg.values, colLabels=dice_df.columns, cellLoc='center', loc='center', rowLabels = ['UNet', 'ResUNet', 'AttUNet'])\n",
    "axs[0].set_title('WT, TC, ET Scores for Testing Dataset')\n",
    "\n",
    "# Plotting ResUNet metrics\n",
    "axs[1].axis('tight')\n",
    "axs[1].axis('off')\n",
    "axs[1].table(cellText=jac_avg.values, colLabels=iou_df.columns, cellLoc='center', loc='center', rowLabels = ['UNet', 'ResUNet', 'AttUNet'])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(10, 20))\n",
    "\n",
    "# Plotting UNet metrics\n",
    "bar(test_metrics_df, \"UNet\", type = 'Testing', ax=axs[0])\n",
    "\n",
    "# Plotting ResUNet metrics\n",
    "bar(restest_metrics_df, \"ResUNet\", type = 'Testing', ax=axs[1])\n",
    "\n",
    "# Plotting AttUNet metrics\n",
    "bar(atttest_metrics_df, \"AttUNet\", type = 'Testing', ax=axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization for Tumours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(model,\n",
    "                    dataloader,\n",
    "                    treshold=0.33):\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    results = {\"Id\": [],\"image\": [], \"GT\": [],\"Prediction\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            id_, imgs, targets = data['Id'], data['image'], data['mask']\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            logits = model(imgs)\n",
    "            \n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            predictions = (probs >= treshold).float()\n",
    "            predictions =  predictions.cpu()\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "            results[\"Id\"].append(id_)\n",
    "            results[\"image\"].append(imgs.cpu())\n",
    "            results[\"GT\"].append(targets)\n",
    "            results[\"Prediction\"].append(predictions)\n",
    "            \n",
    "            # only 5 pars\n",
    "            if (i > 5):\n",
    "                return results\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "\n",
    "def tumour_graphics(n_slice, img, gt, prediction):\n",
    "    print(\"Image Shape:\", img.shape)\n",
    "    print(\"GT Shape:\", gt.shape)\n",
    "    print(\"Prediction Shape:\", prediction.shape)\n",
    "\n",
    "    # Convert to NumPy for visualization\n",
    "    img_np = img.cpu().numpy() if torch.is_tensor(img) else img\n",
    "    gt_np = gt.cpu().numpy() if torch.is_tensor(gt) else gt\n",
    "    prediction_np = prediction.cpu().numpy() if torch.is_tensor(prediction) else prediction\n",
    "\n",
    "    # Create a maximum intensity projection for the side view\n",
    "    \n",
    "    side_view = np.max(img_np[0, 2, :, :, :], axis=2)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(241)\n",
    "    plt.title('Side View (SAGITTAL VIEW)')\n",
    "    plt.imshow(np.rot90(side_view,2), cmap='bone')\n",
    "    plt.axhline(y=side_view.shape[0] - n_slice, color='r', linestyle='--')  # Indicate current slice\n",
    "    plt.axis('off')\n",
    "    \n",
    "    ax.set_ylabel('Left Side of Brain')\n",
    "    ax.set_xlabel(\"Bottom of Brain\")\n",
    "    \n",
    "    # Adding the side view\n",
    "\n",
    "    ax1 = plt.subplot(242)\n",
    "    plt.title('WT Ground Truth')\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,0, n_slice]== False, gt_np[0,0, n_slice]), cmap='summer', alpha=0.6)\n",
    "    ax1.set_ylabel('Left Side of Brain')\n",
    "    ax1.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax2 = plt.subplot(243)\n",
    "    plt.title('TC Ground Truth')\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,1, n_slice]== False, gt_np[0,1, n_slice]), cmap='rainbow', alpha=0.6)\n",
    "    ax2.set_ylabel('Left Side of Brain')\n",
    "    ax2.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax3 = plt.subplot(244)\n",
    "    plt.title('ET Ground Truth')\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,2, n_slice]== False, gt_np[0,2, n_slice]), cmap='Wistia', alpha=0.6)\n",
    "    ax3.set_ylabel('Left Side of Brain')\n",
    "    ax3.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "\n",
    "    ax4 = plt.subplot(246)\n",
    "    plt.title('WT Prediction')\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,0, n_slice]== False, prediction_np[0,0, n_slice]), cmap='summer', alpha=0.5)\n",
    "    ax4.set_ylabel('Left Side of Brain')\n",
    "    ax4.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax5 = plt.subplot(247)\n",
    "    plt.title('TC Prediction')\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,1, n_slice]== False, prediction_np[0,1, n_slice]), cmap='rainbow', alpha=0.5)\n",
    "    ax5.set_ylabel('Left Side of Brain')\n",
    "    ax5.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax6 = plt.subplot(248)\n",
    "    plt.title('ET Prediction')\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,2, n_slice]== False, prediction_np[0,2, n_slice]), cmap='Wistia', alpha=0.5)\n",
    "    ax6.set_ylabel('Left Side of Brain')\n",
    "    ax6.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(11, 5))  # Adjusted the figsize to make it wider for one row of images\n",
    "\n",
    "    plt.subplot(241)\n",
    "    plt.title('Ground Truth')\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,0,n_slice,:,:] == False, gt_np[0,0,n_slice,:,:]),\n",
    "               cmap='summer', alpha=0.8)\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,1,n_slice,:,:] == False, gt_np[0,1,n_slice,:,:]), \n",
    "               cmap='rainbow', alpha=0.8)\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,2,n_slice,:,:] == False, gt_np[0,2,n_slice,:,:]), \n",
    "               cmap='Wistia', alpha=0.8)\n",
    "\n",
    "    ax2 = plt.subplot(242)\n",
    "    ax2.set_facecolor('black')\n",
    "    plt.title(\"Whole Tumour\")\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,0,n_slice,:,:] == False, gt_np[0,0,n_slice,:,:]),\n",
    "               cmap='summer', alpha=0.8)\n",
    "    \n",
    "    ax2.set_ylabel('Left Side of Brain')\n",
    "    ax2.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax3 = plt.subplot(243)\n",
    "    ax3.set_facecolor('black')\n",
    "    plt.title(\"Tumour Core\")\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,1,n_slice,:,:] == False, gt_np[0,1,n_slice,:,:]), \n",
    "               cmap='rainbow', alpha=0.8)\n",
    "\n",
    "    ax3.set_ylabel('Left Side of Brain')\n",
    "    ax3.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax4 = plt.subplot(244)\n",
    "    ax4.set_facecolor('black')\n",
    "    plt.title(\"Enhancing Tumour\")\n",
    "    plt.imshow(np.ma.masked_where(gt_np[0,2,n_slice,:,:] == False, gt_np[0,2,n_slice,:,:]), \n",
    "               cmap='Wistia', alpha=0.8)\n",
    "\n",
    "    ax4.set_ylabel('Left Side of Brain')\n",
    "    ax4.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax5 = plt.subplot(245)\n",
    "    ax5.set_facecolor('black')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(img_np[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,0,n_slice,:,:] == False, prediction_np[0,0,n_slice,:,:]), \n",
    "               cmap='summer', alpha=0.8)\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,1,n_slice,:,:] == False, prediction_np[0,1,n_slice,:,:]), \n",
    "               cmap='rainbow', alpha=0.8)\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,2,n_slice,:,:] == False, prediction_np[0,2,n_slice,:,:]), \n",
    "               cmap='Wistia', alpha=0.8)\n",
    "    \n",
    "    ax5.set_ylabel('Left Side of Brain')\n",
    "    ax5.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax6 = plt.subplot(246)\n",
    "    ax6.set_facecolor('black')\n",
    "    plt.title(\"Whole Tumour\")\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,0,n_slice,:,:] == False, prediction_np[0,0,n_slice,:,:]),\n",
    "               cmap='summer', alpha=0.8)\n",
    "\n",
    "    ax6.set_ylabel('Left Side of Brain')\n",
    "    ax6.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax7 = plt.subplot(247)\n",
    "    ax7.set_facecolor('black')\n",
    "    plt.title(\"Tumour Core\")\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,1,n_slice,:,:] == False, prediction_np[0,1,n_slice,:,:]),\n",
    "               cmap='rainbow', alpha=0.8)\n",
    "    \n",
    "    ax7.set_ylabel('Left Side of Brain')\n",
    "    ax7.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    ax8 = plt.subplot(248)\n",
    "    ax8.set_facecolor('black')\n",
    "    plt.title(\"Enhancing Tumour\")\n",
    "    plt.imshow(np.ma.masked_where(prediction_np[0,2,n_slice,:,:] == False, prediction_np[0,2,n_slice,:,:]),\n",
    "               cmap='Wistia', alpha=0.8)\n",
    "    \n",
    "    ax8.set_ylabel('Left Side of Brain')\n",
    "    ax8.set_xlabel(\"Bottom of Brain\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "def generate_3d_plotly(img, prediction, text):\n",
    "    data = img[0, 0, :, :, :]\n",
    "    data1 = prediction[0, 0, :, :, :]\n",
    "    data2 = prediction[0,1,:,:,:]\n",
    "    data3 = prediction[0,2,:,:,:]\n",
    "\n",
    "    # Threshold value\n",
    "    threshold = 0.2\n",
    "\n",
    "    # Extract coordinates and values for the first tensor\n",
    "    coords = (data > threshold).nonzero(as_tuple=False)\n",
    "    z = coords[:, 0].numpy()\n",
    "    y = coords[:, 1].numpy()\n",
    "    x = coords[:, 2].numpy()\n",
    "    values = data[data > threshold].numpy()\n",
    "\n",
    "    # Create a 3D scatter plot for the first tensor\n",
    "    scatter1 = go.Scatter3d(\n",
    "        x=y,\n",
    "        y=x,\n",
    "        z=z,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=values,  # Color by the actual value\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.2\n",
    "        ),\n",
    "        name='Tensor 1'\n",
    "    )\n",
    "\n",
    "    # Extract coordinates and values for the second tensor\n",
    "    coords1 = (data1 > threshold).nonzero(as_tuple=False)\n",
    "    z1 = coords1[:, 0].numpy()\n",
    "    y1 = coords1[:, 1].numpy()\n",
    "    x1 = coords1[:, 2].numpy()\n",
    "    values1 = data1[data1 > threshold].numpy()\n",
    "\n",
    "    # Create a 3D scatter plot for the second tensor\n",
    "    scatter2 = go.Scatter3d(\n",
    "        x=y1,\n",
    "        y=x1,\n",
    "        z=z1,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=values1,  # Color by the actual value\n",
    "            colorscale='YlGn',\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        name='Whole Tumour'\n",
    "    )\n",
    "\n",
    "    coords2 = (data2 > threshold).nonzero(as_tuple=False)\n",
    "    z2 = coords2[:, 0].numpy()\n",
    "    y2 = coords2[:, 1].numpy()\n",
    "    x2 = coords2[:, 2].numpy()\n",
    "    values2 = data2[data2 > threshold].numpy()\n",
    "\n",
    "    # Create a 3D scatter plot for the second tensor\n",
    "    scatter3 = go.Scatter3d(\n",
    "        x=y2,\n",
    "        y=x2,\n",
    "        z=z2,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=values2,  # Color by the actual value\n",
    "            colorscale='Purples',\n",
    "            opacity=0.5\n",
    "        ),\n",
    "        name='Tumour Core'\n",
    "    )\n",
    "\n",
    "    coords3 = (data3 > threshold).nonzero(as_tuple=False)\n",
    "    z3 = coords3[:, 0].numpy()\n",
    "    y3 = coords3[:, 1].numpy()\n",
    "    x3 = coords3[:, 2].numpy()\n",
    "    values3 = data3[data3 > threshold].numpy()\n",
    "\n",
    "\n",
    "    yellow_colorscale = [\n",
    "        [0, 'rgb(255,255,204)'],\n",
    "        [0.25, 'rgb(255,255,153)'],\n",
    "        [0.5, 'rgb(255,255,102)'],\n",
    "        [0.75, 'rgb(255,255,51)'],\n",
    "        [1, 'rgb(255,255,0)']\n",
    "    ]\n",
    "\n",
    "    # Create a 3D scatter plot for the second tensor\n",
    "    scatter4 = go.Scatter3d(\n",
    "        x=y3,\n",
    "        y=x3,\n",
    "        z=z3,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=values3,  # Color by the actual value\n",
    "            colorscale=yellow_colorscale,\n",
    "            opacity=0.4\n",
    "        ),\n",
    "        name='Enhancing Tumour'\n",
    "    )\n",
    "\n",
    "    # Create the layout\n",
    "    layout = go.Layout(\n",
    "        title=f'3D Scatter Plot of Brain Tumour ({text})',\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Combine the scatter plots\n",
    "    # fig = go.Figure(data=[scatter1, scatter2, scatter3, scatter4], layout=layout)\n",
    "    fig = go.Figure(data=[ scatter2, scatter3, scatter4], layout=layout)\n",
    "    # Show the plot\n",
    "    plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result = ShowResult()\n",
    "BRAIN_INDEX = 1\n",
    "n_slices = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='tumourCSV.csv', phase='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet = medcam.inject(UNet, output_dir=\"UNet_attention_maps\", save_maps=True, backend=\"gcam\")\n",
    "# UNet.medcam_dict['channels'] = 3\n",
    "# Uncomment the top two lines of code for GradCAM\n",
    "\n",
    "results = compute_results(\n",
    "    UNet, test_dataloader, 0.33)\n",
    "\n",
    "print(results['Id'])\n",
    "id_list = []\n",
    "img_list = []\n",
    "gt_list = []\n",
    "prediction_list = []\n",
    "\n",
    "\n",
    "for id_, img, gt, prediction in zip(results['Id'],\n",
    "                    results['image'],\n",
    "                    results['GT'],\n",
    "                    results['Prediction']\n",
    "                    ):\n",
    "    \n",
    "    id_list.append(id_)\n",
    "    img_list.append(img)\n",
    "    gt_list.append(gt)\n",
    "    prediction_list.append(prediction)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slices = 100\n",
    "interact(tumour_graphics, n_slice=widgets.IntSlider(min=0, max=n_slices-1, step=1, value=0), img=fixed(img_list[BRAIN_INDEX]), gt=fixed(gt_list[BRAIN_INDEX]), prediction=fixed(prediction_list[BRAIN_INDEX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_3d_plotly(img_list[BRAIN_INDEX], prediction_list[BRAIN_INDEX], \"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_3d_plotly(img_list[BRAIN_INDEX], gt_list[BRAIN_INDEX], 'GT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result = ShowResult()\n",
    "show_result.plot(img_list[BRAIN_INDEX], gt_list[BRAIN_INDEX], prediction_list[BRAIN_INDEX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for ResUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResUNet = medcam.inject(ResUNet, output_dir=\"ResUNet_attention_maps\", save_maps=True, backend=\"gcam\")\n",
    "# ResUNet.medcam_dict['channels'] = 3\n",
    "# Uncomment the top two lines of code for GradCAM\n",
    "\n",
    "results = compute_results(\n",
    "    ResUNet, test_dataloader, 0.33)\n",
    "\n",
    "print(results['Id'])\n",
    "\n",
    "res_id_list = []\n",
    "res_img_list = []\n",
    "res_gt_list = []\n",
    "res_prediction_list = []\n",
    "for resid_, res_img, res_gt, res_prediction in zip(results['Id'],\n",
    "                    results['image'],\n",
    "                    results['GT'],\n",
    "                    results['Prediction']\n",
    "                    ):\n",
    "    \n",
    "    res_id_list.append(resid_)\n",
    "    res_img_list.append(res_img)\n",
    "    res_gt_list.append(res_gt)\n",
    "    res_prediction_list.append(res_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_slices = 100\n",
    "print()\n",
    "interact(tumour_graphics, n_slice=widgets.IntSlider(min=0, max=n_slices-1, step=1, value=0), img=fixed(res_img_list[BRAIN_INDEX]), gt=fixed(res_gt_list[BRAIN_INDEX]), prediction=fixed(res_prediction_list[BRAIN_INDEX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_3d_plotly(res_img_list[BRAIN_INDEX], res_prediction_list[BRAIN_INDEX], 'Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_3d_plotly(res_img_list[BRAIN_INDEX], res_gt_list[BRAIN_INDEX], \"GT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_result.plot(res_img_list[BRAIN_INDEX], res_gt_list[BRAIN_INDEX], res_prediction_list[BRAIN_INDEX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for AttUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results_attention(model,\n",
    "                    dataloader,\n",
    "                    treshold=0.33):\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    results = {\"Id\": [],\"image\": [], \"GT\": [],\"Prediction\": [],\"Attention\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            id_, imgs, targets = data['Id'], data['image'], data['mask']\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            logits = model(imgs)\n",
    "\n",
    "            attention = AttUNet.dec4.attention_gate.output[1]\n",
    "            attention_map = attention(logits)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            predictions = (probs >= treshold).float()\n",
    "            predictions =  predictions.cpu()\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "            results[\"Id\"].append(id_)\n",
    "            results[\"image\"].append(imgs.cpu())\n",
    "            results[\"GT\"].append(targets)\n",
    "            results[\"Prediction\"].append(predictions)\n",
    "            results[\"Attention\"].append(attention_map)\n",
    "\n",
    "            torch.cuda.empty_cache()            \n",
    "            \n",
    "            # only 5 pars\n",
    "            if (i > 5):\n",
    "                return results\n",
    "        return results\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttUNet = medcam.inject(AttUNet, output_dir=\"AttUNet_attention_maps\", save_maps=True, backend=\"gcam\")\n",
    "# AttUNet.medcam_dict['channels'] = 3\n",
    "# Uncomment the top two lines of code for GradCAM\n",
    "\n",
    "results= compute_results_attention(\n",
    "    AttUNet, test_dataloader, 0.33)\n",
    "    \n",
    "\n",
    "att_id_list = []\n",
    "att_img_list = []\n",
    "att_gt_list = []\n",
    "att_prediction_list = []\n",
    "explain_att = []\n",
    "\n",
    "for attid_, att_img, att_gt, att_prediction, attention in zip(results['Id'],\n",
    "                    results['image'],\n",
    "                    results['GT'],\n",
    "                    results['Prediction'],\n",
    "                    results['Attention']\n",
    "\n",
    "                    ):\n",
    "    \n",
    "    att_id_list.append(attid_)\n",
    "    att_img_list.append(att_img)\n",
    "    att_gt_list.append(att_gt)\n",
    "    att_prediction_list.append(att_prediction)\n",
    "    explain_att.append(attention)\n",
    "\n",
    "print(att_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slices = 100\n",
    "BRAIN_INDEX = 6\n",
    "interact(tumour_graphics, n_slice=widgets.IntSlider(min=0, max=n_slices-1, step=1, value=0), img=fixed(att_img_list[BRAIN_INDEX]), gt=fixed(att_gt_list[BRAIN_INDEX]), prediction=fixed(att_prediction_list[BRAIN_INDEX]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_3d_plotly(att_img_list[BRAIN_INDEX], att_prediction_list[BRAIN_INDEX], \"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_3d_plotly(att_img_list[BRAIN_INDEX], att_gt_list[BRAIN_INDEX], \"GT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAIN_INDEX = 5\n",
    "show_result.plot(att_img_list[BRAIN_INDEX], att_gt_list[BRAIN_INDEX], att_prediction_list[BRAIN_INDEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\GIF/'\n",
    "title = \"Ground Truth_\" + id_[0]\n",
    "filename1 = path + title + \"_3d.gif\"\n",
    "print(res_gt.shape)\n",
    "data_to_3dgif = Image3dToGIF3d(img_dim = (170, 170, 100), binary=False, normalizing=False)\n",
    "transformed_data = data_to_3dgif.get_transformed_data(res_gt[0,0,:,:,:].numpy())\n",
    "data_to_3dgif.plot_cube(\n",
    "    transformed_data,\n",
    "    title=title,\n",
    "    make_gif=True,\n",
    "    path_to_save=filename1\n",
    ")\n",
    "#show_gif(filename1, format='png')\n",
    "\n",
    "title = \"Ground Truth_\" + id_[0]\n",
    "filename1 = title + \"_3d.gif\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradCAMDisplay(img, gt, prediction, WT_file, TC_file, ET_file ,idx):\n",
    "    \n",
    "    WT = nib.load(WT_file)\n",
    "    WT = np.asanyarray(WT.dataobj)\n",
    "\n",
    "    TC = nib.load(TC_file)\n",
    "    TC = np.asanyarray(TC.dataobj)\n",
    "\n",
    "    ET = nib.load(ET_file)\n",
    "    ET = np.asanyarray(ET.dataobj)\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots(3, 4, figsize = (12, 10))\n",
    "\n",
    "\n",
    "    ax1[0][0].imshow(img[0,0,idx,:,:], cmap ='bone')    \n",
    "    ax1[0][0].imshow(np.ma.masked_where(WT[:,:,idx] == False, WT[:,:,idx]), cmap ='magma')\n",
    "    ax1[0][0].set_title('GradCAM (WT)')\n",
    "\n",
    "    ax1[0][1].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[0][1].imshow(np.ma.masked_where(gt[0,0,idx,:,:] == False, gt[0,0,idx,:,:]), cmap ='summer')\n",
    "    ax1[0][1].set_title('GT (WT)')\n",
    "\n",
    "    ax1[0][2].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[0][2].imshow(np.ma.masked_where(prediction[0,0,idx,:,:] == False, prediction[0,0,idx,:,:]),\n",
    "            cmap='summer')\n",
    "    ax1[0][2].set_title('Prediction (WT)')\n",
    "\n",
    "    ax1[0][3].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[0][3].set_title('Original Image')\n",
    "\n",
    "\n",
    "\n",
    "    ax1[1][0].imshow(img[0,0,idx,:,:], cmap ='bone')    \n",
    "    ax1[1][0].imshow(np.ma.masked_where(TC[:,:,idx] == False, TC[:,:,idx]), cmap ='magma')\n",
    "    ax1[1][0].set_title('GradCAM (TC)')\n",
    "\n",
    "    ax1[1][1].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[1][1].imshow(np.ma.masked_where(gt[0,1,idx,:,:] == False, gt[0,1,idx,:,:]), cmap ='rainbow')\n",
    "    ax1[1][1].set_title('GT (TC)')\n",
    "\n",
    "    ax1[1][2].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[1][2].imshow(np.ma.masked_where(prediction[0,1,idx,:,:] == False, prediction[0,1,idx,:,:]),\n",
    "            cmap='rainbow')\n",
    "    ax1[1][2].set_title('Prediction (TC)')\n",
    "\n",
    "    ax1[1][3].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[1][3].set_title('Original Image')\n",
    "\n",
    "    ax1[2][0].imshow(img[0,0,idx,:,:], cmap ='bone')    \n",
    "    ax1[2][0].imshow(np.ma.masked_where(ET[:,:,idx] == False, ET[:,:,idx]), cmap ='magma')\n",
    "    ax1[2][0].set_title('GradCAM (ET)')\n",
    "\n",
    "\n",
    "    ax1[2][1].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[2][1].imshow(np.ma.masked_where(gt[0,2,idx,:,:] == False, gt[0,2,idx,:,:]), cmap ='Wistia')\n",
    "    ax1[2][1].set_title('GT (ET)')\n",
    "\n",
    "    ax1[2][2].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[2][2].imshow(np.ma.masked_where(prediction[0,2,idx,:,:] == False, prediction[0,2,idx,:,:]),\n",
    "            cmap='Wistia')\n",
    "    ax1[2][2].set_title('Prediction (ET)')\n",
    "    \n",
    "    ax1[2][3].imshow(img[0,0,idx,:,:], cmap ='bone')\n",
    "    ax1[2][3].set_title('Original Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slices = 100\n",
    "BRAIN_INDEX = 5\n",
    "\n",
    "interact(GradCAMDisplay, idx=widgets.IntSlider(min=0, max=n_slices-1, step=1, value=0), img=fixed(img_list[BRAIN_INDEX]), gt=fixed(gt_list[BRAIN_INDEX]), prediction=fixed(prediction_list[BRAIN_INDEX]), WT_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\UNet_attention_maps\\out\\attention_map_0_0_0.nii'), TC_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\UNet_attention_maps\\out\\attention_map_0_0_1.nii'), ET_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\UNet_attention_maps\\out\\attention_map_0_0_2.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResUNet GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slices = 100\n",
    "BRAIN_INDEX = 2\n",
    "\n",
    "interact(GradCAMDisplay, idx=widgets.IntSlider(min=0, max=n_slices-1, step=1, value=0), img=fixed(res_img_list[BRAIN_INDEX]), gt=fixed(res_gt_list[BRAIN_INDEX]), prediction=fixed(res_prediction_list[BRAIN_INDEX]), WT_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\ResUNet_attention_maps\\out\\attention_map_4_0_0.nii'), TC_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\ResUNet_attention_maps\\out\\attention_map_4_0_1.nii'), ET_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\ResUNet_attention_maps\\out\\attention_map_4_0_2.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttUnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AttUNet GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slices = 100\n",
    "BRAIN_INDEX = 2\n",
    "\n",
    "interact(GradCAMDisplay, idx=widgets.IntSlider(min=0, max=n_slices-1, step=1, value=0), img=fixed(att_img_list[BRAIN_INDEX]), gt=fixed(att_gt_list[BRAIN_INDEX]), prediction=fixed(att_prediction_list[BRAIN_INDEX]), WT_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\AttUNet_attention_maps\\out\\attention_map_2_0_0.nii'), TC_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\AttUNet_attention_maps\\out\\attention_map_2_0_1.nii'), ET_file = fixed(r'C:\\Users\\ethan\\OneDrive\\Desktop\\Thesis Brain Tumour\\AttUNet_attention_maps\\out\\attention_map_2_0_2.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainable Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tumour_graphics_attention_map(n_slice, img, gt, attention):\n",
    "    print(\"Image Shape:\", img.shape)\n",
    "    print(\"GT Shape:\", gt.shape)\n",
    "    print(\"Attention Shape:\", attention.shape)\n",
    "    plt.close('all')\n",
    "    n_slice = n_slice\n",
    "    # Overlay the second set of images on top of the first set\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(221)\n",
    "    plt.title('Original Image with Ground Truth')\n",
    "    plt.imshow(img[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(gt[0,0,n_slice,:,:] == False, gt[0,0,n_slice,:,:]),\n",
    "            cmap='summer', alpha=0.8)\n",
    "    plt.imshow(np.ma.masked_where(gt[0,1,n_slice,:,:] == False, gt[0,1,n_slice,:,:]), \n",
    "            cmap='rainbow', alpha=0.8)\n",
    "    plt.imshow(np.ma.masked_where(gt[0,2,n_slice,:,:] == False, gt[0,2,n_slice,:,:]), \n",
    "            cmap='Wistia', alpha=0.8)\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.title('Whole Tumour with Explainable Attention')\n",
    "    plt.imshow(img[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(attention[0,0, n_slice,:,:].to('cpu') < 0.1, attention[0,0, n_slice,:,:].to('cpu')), cmap='magma', alpha=0.7)\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.title('Enhanced Tumour with Explainable Attention')\n",
    "    plt.imshow(img[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(attention[0,1, n_slice,:,:].to('cpu') < 0.1, attention[0,1, n_slice,:,:].to('cpu')), cmap='magma', alpha=0.7)\n",
    "    \n",
    "\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.title('Tumour Core with Explainable Attention')\n",
    "    plt.imshow(img[0,0,n_slice,:,:], cmap='bone')\n",
    "    plt.imshow(np.ma.masked_where(attention[0,2, n_slice,:,:].to('cpu') < 0.01, attention[0,2, n_slice,:,:].to('cpu')), cmap='magma', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()  # Adjusts spacing between plots to fit them neatly\n",
    "    plt.show()\n",
    "\n",
    "n_slices = 100\n",
    "\n",
    "interact(tumour_graphics_attention_map, n_slice=widgets.IntSlider(min=0, max=n_slices-1, step=1, value=0), img=fixed(att_img_list[BRAIN_INDEX]), gt=fixed(att_gt_list[BRAIN_INDEX]), attention=fixed(explain_att[BRAIN_INDEX]))\n",
    "# # batch size, channels, depth, width, height\n",
    "\n",
    "# explanable attention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NIB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
